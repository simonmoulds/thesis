%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% IMPERIAL COLLEGE LONDON DISSERTATION TEMPLATE 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This file is `icldiss.tex'
%
% This document fulfills the layout requirements for Dissertations
% of the University of London and of Imperial College London.
% To do so it uses the documentclass `icldt' which is provided free 
% of charge under the MIT license. The relevant College regulations,
% and the license are included in the `icldt' manual.
%
% If you print your dissertation for yourself or as a present for
% family, friends or colleagues you probably should use a different
% layout which does not fulfill the College requirements but which
% can look much better.
%
% For further information and for professional layouting and
% printing services please visit www.PrettyPrinting.net
%
% Copyright (c) 2008, Daniel Wagner, www.PrettyPrinting.net
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{icldt}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

% ======================================

\usepackage[T1]{fontenc}
%\usepackage[dvipdfm,pdfborder=false]{hyperref}
%\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{fixltx2e} % subscripts e.g. CO2
\usepackage{multirow,amssymb,amsmath,booktabs,mathtools,longtable}
\usepackage{soul}
\usepackage{lscape}
%\usepackage[subrefformat=parens,labelformat=parens]{subfig}
\usepackage{caption}
%\usepackage[subrefformat=parens,labelformat=parens]{subcaption}
\usepackage[labelformat=simple]{subcaption}
\usepackage{url}

% from copernicus:
%\usepackage[german, english]{babel}
\usepackage{tabularx}
\usepackage{cancel}
%\usepackage{multirow}
\usepackage{supertabular}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{float}
\usepackage{subfig}
\usepackage{rotating}
\nonstopmode

\def\leftalgn{0.45}\def\rightalgn{0.45}
\def\algnrow{\rule{\leftalgn\textwidth}{0ex}&\rule{\rightalgn\textwidth}{0ex}}
% CONSTRAINTS:
% equation label must fit in {1 -\leftalgn -\rightalgn}\textwidth
% \leftalgn must be larger than any text to left of align character
% \rightalgn must be larger than any text to right of align character
\newenvironment{algneqn}{%
  \arraycolsep=0ex\renewcommand\arraystretch{0}%
  \begin{equation}%
  \begin{array}{rl}%
  \algnrow\\}%
 {\\\algnrow%
  \end{array}%
  \end{equation}\ignorespacesafterend%
}
\def\snug#1{\vspace*{-#1\baselineskip}}

% ======================================

\title{Title}
\author{Simon Moulds}
\date{Month Year}
% Please specify you department here.
\department{Civil and Environmental Engineering}
% The college regulations do not require that you mention 
% your supervisor on the titlepage of you dissertation.
% If you want to do so put her name here.
\supervisor{}
% The college regulations do neither require nor forbid 
% a dedication of your dissertation to somebody or something. 
% If you want to include a dedication put the text here. 
\dedication{}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\maketitle

\begin{abstract}
%% \textbf{Write your own abstract here instead of the following 224 words of
%% and about placeholder text.}

``In publishing and graphic design, lorem ipsum (or simply lipsum) is standard
placeholder text used to demonstrate the graphic elements of a document or
visual presentation, such as font, typography, and layout. Lipsum also serves as
placeholder text in mock-ups of visual design projects before the actual words
are inserted into the finished product. When used in this manner, lipsum is also
called greeking.

Even though using `lorem ipsum' often arouses curiosity due to its resemblance
to classical Latin, it is not intended to have meaning. Where text is visible in
a document, people tend to focus on the textual content rather than upon overall
presentation, so publishers use lorem ipsum when displaying a typeface or design
in order to direct the focus to presentation. `Lorem ipsum' also approximates a
typical distribution of letters in English, which helps to shift the focus to
presentation.

The most common lorem ipsum text reads as follows: Lorem ipsum dolor sit amet,
consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et
dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco
laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in
reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia
deserunt mollit anim id est laborum.''

\hfill --- Wikipedia
\end{abstract}

\makededication

\tableofcontents
\listoftables
\listoffigures




\chapter{Introduction}

This chapter...

\section{Hydroflux India}
Over recent decades the green revolution in India has driven substantial environmental change. While the revolution means that India is now self sufficient in food grains \citep{Singh2000}, there has been widespread land cover change and a marked increase in the exploitation of water resources for irrigation \citep{Roy2007}. \citet{Scott2009} observe that irrigation from groundwater extraction represents more than half of the total irrigated area in India, while a survey carried out by \citet{Shah2006} estimates that in north west India, which contains a large proportion of the fertile Gangetic plains, more than 90\% of the cultivated land is irrigated, of which about 90\% is supplied from groundwater. In addition to agricultural use, groundwater resources supply a large proportion of domestic and industrial water demand \citep{Amarasinghe2005}. Regional water demand has caused a gradual depletion of groundwater resources in several locations \citep{Rodell2009}. The pressure on water resources in India, already severe, is likely to increase with forecasted population growth together with continued economic progress. Further, \citet{Goswami2006} showed that, while climate change has not affected mean rainfall, the frequency of heavy rain days has increased while the frequency of light and moderate rain days has decreased. This is consistent with the hypothesis that climate change will cause precipitation in the tropics to become more extreme \citep{Trenberth2003}. \\

Water resources in northern India are dominated by large scale aquifers \citep{Bandy1995}. Variations in recharge due to land cover change and changing irrigation practices, combined with increasing intensification of groundwater extractions, may affect water resources in complex ways. In addition, there is evidence of strong feedbacks between soil moisture and precipitation in the region \citep[e.g.][]{Meehl1994,Koster2004,Niyogi2010}. This arises because soil moisture at the land surface affects the partitioning of latent and sensible heat and surface albedo \citet{Eltahir1998}. Modelling carried out by \citet{Meehl1994} identified the link between soil moisture and the strength of the Asian summer monsoon. The Global Land-Atmosphere Coupling Experiment (GLACE) \citep{Koster2004,Koster2006,Guo2006} provided further evidence of soil moisture-precipitation coupling and identified northern India as one of three global "hot spots" where the soil moisture feedback is especially pronounced due to the sensitivity of evapotranspiration to soil moisture, rather than the available solar radiation, combined with the high variability of evapotranspiration over time. \\

A review by \citet{Seneviratne2010} highlighted that, while multimodel experiments such as GLACE succeed in identifying basic feedback mechanisms, there is wide range of sensitivity of climate to soil moisture between different climate models. \citet{Pitman2009} observed that different assumptions about the physical characteristics of land cover types made by climate models, in terms of the representation of albedo, evapotranspiration and crop phenology, causes model results to differ markedly. Consequently, the impact of land cover change on water resources and fluxes in northern India is highly uncertain. One major source of uncertainty emanates from the lack of a common land cover change dataset to force climate models \citep{Pitman2009}. Additional uncertainty arises by the different land surface parameterisations implemented by different climate models, which is made worse by the fact that these models cannot be calibrated to local conditions. \citet{Seneviratne2010} suggests that this problem could be overcome by using the output of offline, high resolution, physically based land surface models, calibrated using local observed data, to force global climate models. Finally, there is a lack of observations of key hydrological variables to calibrate and verify models. \\

\section{Historical land use/land cover}
TODO

\section{Model coupling}
TODO

\section{Open science}
A central theme of this thesis is the idea that the way in which science is done is of central importance... Models are an essential part of environmental science yet it seems... \\

\subsection{Aim}
The aim of the thesis is to develop tools and methods that improve the quantification... of large-scale environmental change on regional water resources and climate. 

\subsection{Objectives}
To achieve the stated aim the following objectives will be pursued

\begin{enumerate}
  \item Review the current state of the art in land use change modelling and develop an appropriate framework to develop historical land use/land cover maps at a regional scale
  \item Apply the land use change modelling framework to produce a land cover change dataset for India showing environmental change  
  \item Explore ways to incorporate information about land use intensity with land cover data, and develop an historical dataset showing the change in land use intensity since independence
  \item TODO (soil moisture)
  \item TODO (model coupling)
\end {enumerate}

\subsection{Structure of thesis}
TODO

%% The aim of the project is to develop a robust methodology to assess the impact of land cover change on water resources and hydrometeorological feedbacks in northern India. \\ 

%% \subsection{Objectives}

%% To achieve the stated aim the following objectives will be pursued:
%% \begin{enumerate}
%% \item To develop a robust methodology to construct a land use and land cover change dataset for regions where the temporal extent and resolution of remotely sensed data is poor
%% \item To assimilate different types of remotely sensed data to improve the parameterisation and calibration of land surface models and to subsequently use land surface models to produce a reanalysis soil moisture dataset for the study region at very high spatial resolution
%% \item To compare the performance of land surface models with different forcings to assess the impact of land cover change on water fluxes and resources in the study area
%% \item To explore the use of land surface models to map water scarcity and vulnerability at very high spatial and temporal resolution
%% \end{enumerate}

%% %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 
%% %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%% %
%% %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%% %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

%% \subsection{Hypotheses}

%% \begin{description}
%% \item[Hypothesis 1:] Land use change models can be used extrapolate classified satellite images back in time in order to improve the temporal extent of land cover maps
%% \item[Hypothesis 2:] Remotely sensed data can be used in data scarce regions to calibrate land surface models
%% \item[Hypothesis 3:] The integration of a land cover change dataset improves the capacity of land surface models to simulate observed trends in water fluxes and resources in the study area
%% \item[Hypothesis 4:] High resolution, physically based land surface models can be used to understand the processes driving observed hydrometeorological feedbacks in northern India
%% \item[Hypothesis 5:] Landsurface models can be used to map water scarcity and vulnerability at very high spatial and temporal resolution
%% \end{description}

%% \newpage




\chapter{Land use change modelling}

This chapter describes the development of a software package, written in R, for land use change modelling. \\

%% \begin{abstract}
%%   We present the lulcc software package; an object-oriented framework for land use change modelling written in the R programming language. The contribution of the work is to resolve the following limitations associated with the current land use change modelling paradigm: (1) The source code for model implementations is frequently unavailable, severely compromising the reproducibility of scientific results and making it impossible for members of the community to improve or adapt models for their own purposes; (2) Ensemble experiments to capture model structural uncertainty are difficult because of fundamental differences between implementations of alternative models; (3) Additional software is required because existing applications frequently perform only the spatial allocation of change. The package includes a~stochastic ordered allocation procedure as well as an implementation of the CLUE-S algorithm. We demonstrate its functionality by simulating land use change at the Plum Island Ecosystems site, using a~dataset included with the package. It is envisaged that lulcc will enable future model development and comparison within an open environment. \\
%% \end{abstract}

\newpage
%% \introduction
\section{Introduction}

Spatially explicit land use change models are used to understand and quantify key processes that affect land use and land cover change and simulate past and future change \citep{veldkamp2001,mas2014}. These models are commonly implemented in compiled languages such as C/C++ and Fortran and distributed as software packages or extensions to proprietary geographic information systems such as ArcGIS or IDRISI. As \citet{rosa2014} points out, it is uncommon for the source code of land use change modelling software to be made available \citep[e.g.][]{verburg2002,soares-filho2002,verburg2009,schaldach2011}. While it is true that the concepts and algorithms implemented by the software are normally described in scientific journal articles, this fails to ensure the reproducibility of scientific results \citep{peng2011,morin2012}, even in the hypothetical case of a~perfectly described model \citep{ince2012}. In addition, running binary versions of software makes it difficult to detect silent faults (faults that change the model output without obvious signals), whereas these are more likely to be identified if the source code is open \citep{cai2012}. Moreover, it forces duplication of work and makes it difficult for members of the scientific community to improve the code or adapt it for their own purposes \citep{morin2012,pebesma2012,steiniger2013}. In this paper we describe the development of \textbf{lulcc}, a~new R package designed to foster an open approach to land use change science. \\

Current software packages for land use change modelling usually exist as specialised applications that implement one algorithm. Indeed, it is common for applications to perform only one part of the modelling process. For example, the Change in Land Use and it Effects at Small regional extent (CLUE-S) software only performs spatial allocation, requiring the user to prepare model input and conduct the statistical analysis upon which the allocation procedure depends elsewhere \citep{verburg2002}. This is time consuming and increases the likelihood of user errors because inputs to the various modelling stages must be transferred manually between applications. Furthermore, very few programs include methods to validate model output, which could be one reason for the lack of proper validation of models in the literature, as noted by \citet{rosa2014}. The lack of a~common interface amongst land use change models is problematic for the community because there is widespread uncertainty about the appropriate model form and structure for modelling applications \citep{verburg2013}. Under these circumstances it is useful to experiment with various models to identify the model that performs best in terms of calibration and validation \citep{schmitz2009}. Alternatatively, ensemble modelling may be used to understand the impact of structural uncertainty on model outcomes \citep{knutti2012}. However, while some land use change model comparison studies have been carried out \citep[e.g][]{perez-vega2012,mas2014,rosa2014}, fundamental differences between models in terms of scale, resolution and model inputs prevent the widespread use of ensemble land use change predictions \citep{rosa2014}. As a~result, the uncertainty associated with model outcomes is rarely communicated in a~formal way, raising questions about the utility of such models \citep{pontius2005-a}. \\

An alternative approach is to develop frameworks that allow several modelling approaches to be implemented within the same environment. One such application is PCRaster, a~free and open source GIS that includes additional capabilities for spatially explicit dynamic modelling \citep{schmitz2009}. The PCRcalc scripting language and development environment allows users to build models with native PCRaster operations such as map algebra and neighbourhood functions. Alternatively, the PCRaster application programming interface (API) allows users to extend its functionality in various programming languages using native and external data types \citep{schmitz2009}. For example, the current version of FALLOW \citep{vannoordwijk2002,mulia2014}, a deductive land use change model, is built using the PCRaster framework. TerraME \citep{carneiro2013} is a~platform to develop models for simulating interactions between society and the environment. It provides more flexibility than PCRaster because models can be composed of coupled sub-models with various temporal and spatial resolutions \citep{moreira2009,carneiro2013}. The platform is built on the open source TerraLib geospatial library \citep{camara2008}, which handles several spatio-temporal data types, includes an API for coupling the library with R \citep{R2014} to perform spatial statistics, and supports dynamic modelling with cellular automata. The LuccME extension to TerraME includes implementations of CLUE-S and its predecessor, CLUE \citep{veldkamp1996,verburg1999}, written in Lua. \\

The R environment is a~free and open source implementation of the S programming language, a~language designed for programming with data \citep{chambers2008}. Although the development of R is strongly rooted in statistical software and data analysis, it is increasingly used for dynamic simulation modelling in diverse fields \citep{petzoldt2007}. Additionally, in the last decade it has become widely used by the spatial analysis community, largely due to the \textbf{sp} package \citep{pebesma2005,bivand2013} which unified many alternative approaches for dealing with spatial data in R and allowed subsequent package developers to use a~common framework for spatial analysis. The \textbf{raster} package \citep{hijmans2014} provides many functions for raster data manipulation commonly associated with GIS software. Building on these capabilities, several R packages have been created for dynamic, spatially explicit ecological modelling \citep[e.g.][]{petzoldt2007,fiske2011}. In addition, two recent land use change models have been written for the R environment. StocModLCC \citep{rosa2013} is a~stochastic inductive land use change model for tropical deforestation while SIMLANDER \citep{hewitt2013} is a~stochastic cellular automata model to simulate urbanisation. Thus, R is well suited for spatially explicit land use change modelling. To date, however, R has not been used to develop a~framework for land use change model development and comparison. The remainder of this paper is divided into four sections. First, we discuss the principle design goals of \textbf{lulcc}. We then describe the software and demonstrate its main functionality with an example application to the Plum Island Ecosystems site, using data included with the package. This is followed by a~discussion of the strengths and main limitations of the software and approach, as well as areas for future development. Finally we draw brief conclusions from the project.
\\

\section{Design goals}

The first design goal of \textbf{lulcc} is to provide a~framework that allows users to perform various stages of the modelling process illustrated by Figure~\ref{fig:flowchart} within the same environment. It therefore includes methods to process and explore model input, fit and evaluate predictive models, allocate land use change spatially, validate the model and visualise model outputs. This provides many advantages over specialised software applications. Firstly, it improves efficiency and reduces the likelihood of user errors because intermediate inputs and outputs exist in the same environment \citep{fiske2011,pebesma2012}. Secondly, it encourages interactive model building because seperate aspects of the procedure can easily be revisited. Thirdly, it is straightforward to experiment with different model setups. Finally, and perhaps most importantly, it improves the reproducibility of scientific results because the entire modelling process can be expressed programmatically and be communicated as such with reasonable effort \citep{pebesma2012}. \\ 

\textbf{lulcc} is intended as an alternative to current paradigm of closed source, specialised software programs which, in our view, disrupt the scientific process. Thus, the second design goal is to create an open and extensible framework allowing users to examine the source code, modify it for their own purposes and freely distribute changes to the wider community. The package exploits the openness of the R system, particularly with respect to the package system, which allows developers to contribute code, documentation and datasets in a~standardised format to repositories such as the Comprehensive R Archive Network (CRAN) \citep{pebesma2012,claes2014}. As a~result of this philosophy R users have access to a~wide range of sophisticated tools for statistical modelling, data management, spatial analysis and visualisation. \\

One of the consequences of providing a~modelling framework in R is that users of the software must become programmers \citep{chambers2000}. We recognise that this represents a~different approach to the current practice of providing land use change software packages with graphical user interfaces (GUIs), and acknowledge that for users unfamiliar with programming it could present a~steep learning curve. Therefore, the third design goal is to provide well documented software that is easy to use and accessible for a~users with varying levels of programming experience. The package includes complete working examples to allow beginners to start using the package immediately from the R command shell, while more advanced users should be able to develop modelling applications as scripts. Furthermore, the package is designed to be extensible so that users can contribute new or existing methods. Similarly, the source code of \textbf{lulcc} is accessible so that users can locate the methods in use and understand algorithm implementations. Acknowledging that many scientists lack any formal training in programming \citep{joppa2013,wilson2014}, we hope this final goal will ensure the software is useful for educational purposes as well as scientific research. \\

\section{Software description}

To achieve the design goals we adopted an object-oriented approach. This provides a~formal structure for the modelling framework which allows the various stages of land use change modelling applications to be handled efficiently. Furthermore, it encourages the reuse of code because objects can be used multiple times within the same application or across several different applications. It is extensible because it is straightforward to extend existing classes using the concept of inheritance, or create new methods for existing classes. In \textbf{lulcc} we use the S4 class system \citep{chambers1998,chambers2008}, which requires classes and methods to be formally defined. This system is more rigorous than the alternative S3 system because objects are validated against the class definition when they are created, ensuring that objects behave consistently when they are passed to functions and methods. Figure~\ref{fig:classdiagram} shows the class structure of \textbf{lulcc}, while Table~\ref{table:functions} shows the functions included with the package. Here we describe the main components of \textbf{lulcc} integrated with an example application for the Plum Island Ecosystems dataset. The script used in this paper, including the code used to create the various figures, is supplied with the package as a~``demo". Instructions to obtain the package and run the demo script are provided in the Code availability section. \\

\subsection{Data}

The failure to provide driving data for land use change modelling exercises alongside published literature is identified by \citet{rosa2014} as a~major weakness of the discipline. The \textbf{lulcc} package includes two datasets that have been widely used in the land use change community, allowing users to quickly start exploring the modelling framework. The first of these contains data from the Plum Island Ecosystems Long Term Ecological Research site in northeast Massachusetts (\url{http://pie-lter.ecosystems.mbl.edu/}), which in recent decades has undergone extensive land use change from forest to residential use \citep{aldwaik2012}. The dataset included in \textbf{lulcc} was originally developed as part of the MassGIS program \citep{massgis2015} but has been processed by \citet{pontius2014}. Land use maps depicting forest, residential and other uses are available for 1985, 1991 and 1999 together with maps of three predictor variables: elevation, slope and distance to built land in 1985. The second dataset includes information from Sibuyan Island in the Phillipines, and is a~modified version of the dataset supplied with the CLUE-S model \citep{verburg2002}.

\subsection{Data processing}

One of the most challenging aspects of land use change modelling is to obtain and process the correct input data. Currently \textbf{lulcc} requires all spatially explicit input data to exist either in the file system, in any of the formats supported by \textbf{raster}, or in the R workspace as \textbf{raster} objects (RasterLayer, RasterStack or RasterBrick). The most fundamental input required by land use change models is an initial map of observed land use, which is usually obtained from classified remotely sensed data. This map represents the initial condition for model simulations and, for inductive modelling, is used to fit predictive models. Sometimes it is more useful to consider observed land use transitions: in this case an additional map for an earlier time point is required, as shown by Figure~\ref{fig:flowchart}. Ideally, two more observed land use maps for subsequent time points should be obtained for calibrating and validating the land use change model \citep{pontius2004-a}. The current version of the software only supports categorical land use data, which means that each pixel must belong to exactly one category. \\

In \textbf{lulcc} observed land use data are represented by the ObsLulcRasterStack class. In the following code snippet we load the package into the current session, create an ObsLulcRasterStack object for the Plum Island Ecosystems dataset and plot the result (Figure~\ref{fig:pie}):
\begin{verbatim}
> library(lulcc)
> data(pie)
> obs <- ObsLulcRasterStack(x=pie,
                            pattern="lu",
                            categories=c(1,2,3),
                            labels=c("Forest","Built","Other"),
                            t=c(0,6,14))
> plot(obs)
\end{verbatim} 

\noindent The ObsLulcRasterStack object is important to land use change studies in \textbf{lulcc} because it defines the spatial domain of subsequent operations. The \texttt{t} argument in the constructor function specifies the time points associated with the observed land use maps. The first time point must always be zero; if additional maps are present they should be associated with time points greater than zero, even in backcast models. In most land use change modelling applications the timestep between two time points represents one year but there is no requirement for this to be the case. \\

A useful starting point in land use change modelling is to obtain a~transition matrix for observed land use maps from two time points to identify the main historical transitions in the study region \citep{pontius2004}, which can be used as the basis for further research into the processes driving change. In \textbf{lulcc} we use the \texttt{crossTabulate} function for this purpose:
\begin{verbatim}
> crossTabulate(x=obs, times=c(0,14)) 
       Forest Built Other
Forest 44107   4250   656
Built     11  36957   154 
Other   1259   2248 23921
\end{verbatim}
\noindent The output of this command reveals that for the Plum Island Ecosystems site the dominant change between 1985 and 1999 was the conversion of forest to built areas. \\

Inductive and deductive land use change models predict the allocation of change based on spatially explicit biophysical and socioeconomic explanatory variables. These may be static, such as elevation or geology, or dynamic, such as maps of population density or road networks. In \textbf{lulcc} these two types of explanatory variable are separated by a~simple naming convention, which is explained in detail in the package documentation (see Supplementary material). Collectively, they are represented by an object of class ExpVarRasterList, which can be created as follows:
\begin{verbatim}
> ef <- ExpVarRasterList(x=pie, pattern="ef")
\end{verbatim}
\noindent Apart from observed land use and explanatory variables other input maps may be required. The two allocation routines currently included with \textbf{lulcc} accept a~mask file, which is used to prevent change within a~certain geographic area such as a~national park or other protected area, and a~land use history file, which is used as the basis for certain decision rules. These are handled by \textbf{lulcc} as standard RasterLayer objects. All input maps should have the same spatial resolution as the corresponding ObsLulcRasterStack object. This can be achieved using the \texttt{resample} function from the \textbf{raster} package, which has been extended to receive lulcc objects. The ExpVarRasterList object created above can be resampled to the parameters of an ObsLulcRasterStack object with the following command:
\begin{verbatim}
> ef <- resample(ef, obs)
\end{verbatim}

\subsection{Predictive modelling}

Inductive land use change models relate the pattern of observed land use to spatially explicit explanatory variables. Logistic regression is a common type of predictive model used for inductive land use change modelling \citep[e.g.][]{pontius2001,verburg2002}. However, there is growing interest in the application of local and non-parametric models \citep[e.g.][]{tayyebi2014}. One reason why R is attractive for land use change modelling is that it has become the \textit{de facto} standard for statistical software development. As a~result, \textbf{lulcc} can easily support various predictive modelling techniques by utilising code from existing R packages. Currently, \textbf{lulcc} supports binary logistic regression, available in base R, recursive partitioning and regression trees, provided by the \textbf{rpart} package \citep{therneau2014}, and random forests, provided by the \textbf{randomForest} package \citep{liaw2002}. \\

Parametric models such as logistic regression assume the data to be independent and identically distributed \citep{overmars2003}. In spatial analysis this assumption is often violated because of spatial autocorrelation, which reduces the information content of an observation because its value can to some extent be predicted by the value of its neighbours \citep{beale2010}. There is also some evidence that non-parametric models may be affected by spatial autocorrelation \citet{mascaro2014}, even though they do not assume independence. A~simple approach to reduce the impact of this phenomenon is to fit predictive models to a~random subset of the data \citep[e.g.][]{verburg2002,wassenaar2007,echeverria2008}. In the following code snippet we create training and testing partitions for the Plum Island Ecosystems dataset by performing a~stratified random sample. We do this using the map for 1985 to illustrate the procedure when only one observed map is available. We then extract the data for the training partition with the \texttt{getPredictiveModelInputData} function and pass the resulting data.frame to the three model fitting functions:
\begin{verbatim}
> part <- partition(x=obs[[1]], size=0.1, spatial=TRUE) 
> train.data 
       <- getPredictiveModelInputData(obs=obs, 
                                      ef=ef, 
                                      cells=part[["train"]], 
                                      t=0) 

> forms <- list(Built~ef_001+ef_002+ef_003, 
                Forest~ef_001+ef_002, 
                Other~ef_001+ef_002) 

> glm.models   <- glmModels(formula=forms, 
                            family=binomial, 
                            data=train.data, 
                            obs=obs) 

> rpart.models <- rpartModels(formula=forms, 
                              data=train.data, 
                              obs=obs) 

> rf.models    <- randomForestModels(formula=forms, 
                                     data=train.data, 
                                     obs=obs)
\end{verbatim}
\noindent The model fitting functions each return an object of class PredictiveModelList containing a~predictive model for each land use type. With these objects it straightforward to map the suitability of every pixel in the study region to the various land uses. To do this, we use the generic \texttt{predict} function with some additional functionality from the \textbf{raster} package and plot the resulting RasterStack object (Figure~\ref{fig:suitability}):
\begin{verbatim}
> all.data <- as.data.frame(x=ef, cells=part[["all"]]) 
> probmaps <- predict(object=glm.models, 
                      newdata=all.data, 
                      data.frame=TRUE) 
> points   <- rasterToPoints(obs[[1]], spatial=TRUE) 
> probmaps <- SpatialPointsDataFrame(points, probmaps) 
> probmaps <- rasterize(x=probmaps, y=obs[[1]], 
                        field=names(probmaps)) 
> levelplot(probmaps)
\end{verbatim}

In some circumstances it may be appropriate to supply a~model with no explanatory variables to an allocation routine. For example, \citet{verburg2009} used such a~model for natural and semi-natural vegetation because in their particular case study the selection of pixels for conversion to these land uses was based on the suitability of pixels to agricultural and urban land rather than the suitability of natural and semi-natural vegetation. In lulcc, this can most easily be achieved by fitting a~binary logistic regression model with no explanatory variables. To do this, a~formula such as \texttt{Forest\textasciitilde1} should be supplied to the \texttt{glmModels} function. \\

Methods to evaluate statistical models are provided by the \textbf{ROCR} package \citep{sing2005}, allowing the user to assess model performance using various methods including the receiver operator characteristic (ROC), which is used to measure the performance of models predicting the presence or abscence of a~phenomenon \citep{pontius2014}. It is often summarised by the area under the curve (AUC), where one indicates a~perfect fit and 0.5 indicates a~purely random fit. \\

In \textbf{lulcc} we extend the native \textbf{ROCR} classes to better suit our purposes. The prediction and performance classes of \textbf{ROCR} are extended by PredictionList and PerformanceList, respectively, to handle objects of class PredictiveModelList. In the folliwing example we evaluate the logistic regression models using the testing partition from the 1985 observed land use map. Since the Plum Island Ecosystems dataset contains three observed land use maps we could also test the predictive models using data from a subsequent time point. The procedure to evaluate several PredictiveModelList objects using these classes is as follows:
\begin{verbatim}
> test.data  
      <- getPredictiveModelInputData(obs=obs, 
                                     ef=ef, 
                                     cells=part[["test"]]) 
> glm.pred   <- PredictionList(models=glm.models, 
                               newdata=test.data) 
> glm.perf   <- PerformanceList(pred=glm.pred, 
                                measure="rch") 
> rpart.pred <- PredictionList(models=rpart.models, 
                               newdata=test.data) 
> rpart.perf <- PerformanceList(pred=rpart.pred, 
                                measure="rch") 
> rf.pref    <- PredictionList(models=rf.models, 
                               newdata=test.data) 
> rf.perf    <- PerformanceList(pred=rf.pred, 
                                measure="rch") 
> plot(list(glm=glm.perf, rpart=rpart.perf, rf=rf.perf)) 
\end{verbatim}
\noindent Figure~\ref{fig:roc} shows the ROC curves for each land use type and for each type of predictive model supported by \textbf{lulcc}. The plots show that binary logistic regression and random forest models perform similarly for all land uses, while regression tree models perform least well. \\

Another use of ROC analysis is to assess how well the models predict the cells in which gain occurs between two time points. This is only possible if a~second observed land use map is available for a~subsequent time point. In the following code snippet we perform this type of analysis for the gain of Built between 1985 and 1991. First, we create a~data partition in which cells not candidate for gain (cells belonging to Built in 1985) are eliminated. We then assess the ability of the various predictive models to predict the gain of Built in this partition:
\begin{verbatim}
> part <- rasterToPoints(obs[[1]], 
                         fun=function(x) x != 2, 
                         spatial=TRUE) 
> test.data <- getPredictiveModelInputData(obs=obs, 
                                           ef=ef, 
                                           cells=part, 
                                           t=6) 
> glm.pred  <- Prediction(models=glm.models[[2]], 
                          newdata=test.data) 
> glm.perf  <- Performance(pred=glm.pred, 
                           measure="rch") 
> plot(list(glm=glm.perf))
\end{verbatim}
\noindent Figure~\ref{fig:builtgain} shows the resulting ROC curve. \\

\subsection{Demand}

Spatially explicit land use change models are normally driven by non-spatial estimates of either the total number of cells occupied by each category at each time point or the number of transitions among the various categories during each time interval. This means regional drivers of land use change, such as population growth and technology, are considered implicitly \citep{fuchs2013}. While some models calculate demand at each time point based on the spatial configuration of the landscape at the previous time point \citep[e.g.][]{rosa2013}, it is more common to specify the demand for every time point at the beginning of the simulation \citep[e.g.][]{pontius2001,verburg2002,sohl2007}. In \textbf{lulcc} the way in which demand is specified is unique to individual allocation models. Currently, both allocation models currently included in the package require the total number of cells belonging to each category at every time point to be supplied as a~matrix or data.frame before running the allocation routine. \\

Land use area may be estimated using non-spatial land use models or, in the case of a~backcast model, national and subnational land use statistics may be used \citep[e.g.][]{ray2010,fuchs2013}. \textbf{lulcc} includes a~function to interpolate or extrapolate land use area based on two or more observed land use maps: this approach is often used to predict the quantity of land use change in the near-term \citep{mas2014}. For the current example we obtain land use demand for each year between 1985 and 1999 by linear interpolation, as follows:
\begin{verbatim}
> dmd <- approxExtrapDemand(obs=obs, tout=0:14)
\end{verbatim}
\noindent In reality we are not usually interested in simulating land use change between two time points for which observed land use data is available. However, doing so is useful for model pattern validation, allowing us to test the ability of models to predict the spatial allocation of change given the exact quantity of change. \\

\subsection{Allocation}
The allocation algorithm in land use change models determines the pixels in which various land use transitions should take place \citep{verburg2002}. Currently \textbf{lulcc} includes two allocation routines: an implementation of the CLUE-S algorithm and a~stochastic ordered procedure based on the algorithm described by \citet{fuchs2013}. Both routines allow the user to optionally provide various decision rules. These are implemented before the main allocation algorithm at each time point and allow the user to incorporate additional knowledge about the study site. \\

\subsubsection{Decision rules}

The first decision rule included in \textbf{lulcc} is used to prohibit certain land use transitions. For example, in most situations it is unlikely that urban areas will be converted to agricultural land because the initial cost of urban development is high \citep{verburg2002}. The second rule specifies a~minimum number of timesteps before a~certain transition is allowed, while the third rule specifies a~maximum number of timesteps after which change is not allowed. These rules are used to control land use transitions that are time-dependent, such as the transition from shrubland to closed forest \citep{verburg2009}. The fourth rule prohibits transitions to a~certain land use in cells that are not within a~user-defined neighbourhood of cells already belonging to that land use. This rule is particularly relevant to cases of deforestation or urbanisation. \\

Within the \texttt{allocate} function the first three decision rules are applied by the \texttt{allow} function and the fourth rule is applied by the \texttt{allowNeighb} function. For time dependent decision rules the user should supply a land use history raster map, specifying the length of time each pixel has belonged to the current land use. If this is not supplied each pixel is assigned a value of one, representing one model timestep. To apply neighbourhood rules it is necessary to supply corresponding neighbourhood maps to the allocation routine. In \textbf{lulcc} these are represented by the \texttt{NeighbRasterStack} class. Objects of this class are created with the following command:
\begin{verbatim}
> w  <- matrix(data=1, nrow=3, ncol=3)
> nb <- NeighbRasterStack(x=obs[[1]], weights=w, 
                          categories=c(1,2,3))
\end{verbatim}

Essentially, the \texttt{allow} and \texttt{allowNeighb} functions identify disallowed transitions according to the decision rules and set the suitability of these cells to NA. These transitions are ignored by the allocation routine. Care should be taken to ensure that after any decision rules are taken into account there are sufficient cells eligible to change in order to meet the specified demand at each time point. \\

\subsubsection{CLUE-S allocation method}

The CLUE-S model implements an iterative procedure to meet the specified demand at each time point and handle competition between land uses. The model is summarised briefly here: for a~full description see \citet{verburg2002} and \citet{castella2007}. The algorithm in \textbf{lulcc} is based on the description of the model provided by \citet{verburg2002} only. As a~result, for the reasons discussed by \citet{ince2012}, users should not expect to exactly reproduce the output from the original model implementation. \\

In the first instance each cell is allocated to the land use with the highest suitability as determined by the predictive models. Whereas the original CLUE-S model is based on binary logistic regression, \textbf{lulcc} allows any predictive model supported by PredictiveModelList to be used. For each land use the algorithm determines whether the allocated area is less than, equal to or greater than the specified demand. If it is less than or greater than demand the suitability of each pixel in the study region to the land use in question is increased or decreased, respectively, by an amount depending on the difference between the allocated area and specified demand. If the allocated area equals demand the suitability is left unchanged. This procedure is repeated until the demand for all land uses, within a~user-defined tolerance, is met. At each iteration the original model perturbs the suitability of each pixel to the various land uses in order to limit the influence of nominal differences in land use suitability on the final model solution. This is replicated in \textbf{lulcc} with the parameter \texttt{jitter.f}, which controls the upper and lower limits of the uniform random distribution from which the perturbation applied to each pixel is drawn. The default value of \texttt{jitter.f} is zero, resulting in a~deterministic model. For a~full description of the various other parameters supplied to the CLUE-S routine please consult the package documentation. \\

In \textbf{lulcc} allocation models are represented by unique classes. In the following code snippet we first set the decision rules to allow all possible transitions and then define some parameter values. Then, we create an object of class CluesModel and pass this to the generic \texttt{allocate} function:
\begin{verbatim}
> clues.rules <- matrix(data=1, nrow=3, ncol=3) 
> clues.parms <- list(jitter.f=0.0002, 
                      scale.f=0.000001, 
                      max.iter=1000, 
                      max.diff=50, 
                      ave.diff=50) 
> clues.model <- CluesModel(obs=obs, 
                            ef=ef, 
                            models=glm.models, 
                            time=0:14, 
                            demand=dmd, 
                            elas=c(0.2,0.2,0.2), 
                            rules=clues.rules, 
                            params=clues.parms) 
> clues.model <- allocate(clues.model)
\end{verbatim}
\noindent As an iterative procedure the CLUE-S algorithm employs for-loops, which are slow in R. To overcome this limitation we have written the CLUE-S procedure as a~C extension using the .Call interface. \\

\subsubsection{Ordered method}

The ordered allocation method is based on the algorithm described by \citet{fuchs2013}. The approach is less computationally expensive and more stable than the CLUE-S algorithm because it doesn't simulate competition between land uses. Instead, land allocation is performed in a~hierarchical way according to the perceived socioeconomic value of each land use. For land uses with increasing demand only cells belonging to land uses with lower socioeconomic value are considered for conversion. In this case, \textit{n} cells with the highest suitability to the current land use are selected for change, where \textit{n} equals the number of transitions required to meet the demand, as specified by the demand matrix supplied as an input to the allocation routine. The converted cells, as well as the cells that remain under the current land use, are masked from subsequent operations. For land uses with decreasing demand only cells belonging to the current land use are allowed to change. Here, \textit{n} cells with the lowest allocation suitability are converted to a~temporary class which can be allocated to subsequent land uses. The land use with the lowest socioeconomic value is a~special case because it is considered last and, therefore, the number of cells that have not been assigned to other land uses must equal the demand for this land use. \\

We modify the algorithm described by \citep{fuchs2013} to allow stochastic transitions. If this option is selected, the allocation suitability of each cell allowed to change is compared to a~random number between zero and one drawn from a~uniform distribution. If demand for the land use is increasing only cells where the allocation suitability is greater than the random number are allowed to change, whereas for decreasing demand only cells where it is less than the random number are allowed to change. To make the model deterministic the user can set the \texttt{stochastic} argument to FALSE when the \texttt{allocate} function is called. \\

In \textbf{lulcc} the ordered allocation model is represented by the OrderedModel class. In the following code we create an OrderedModel object, supplying the order in which to allocate change (built, forest, other), and pass this to the \texttt{allocate} function:
\begin{verbatim}
> ordered.model <- OrderedModel(obs=obs, 
                                ef=ef, 
                                models=glm.models, 
                                time=0:14, 
                                demand=dmd, 
                                order=c(2,1,3)) 
> ordered.model <- allocate(ordered.model, stochastic=TRUE)
\end{verbatim}

\subsection{Pattern validation}

Spatially explicit land use change models are validated by comparing the initial observed map with an observed and simulated map for a~subsequent time point \citep{pontius2011}. Previous studies have extracted useful information from the three possible two-map comparisons \citep[e.g.][]{pontius2008}, however, recently \citet{pontius2011} devised the concept of a~three-dimensional contingency table to compare the three maps simulataneously. Not only is this approach more parsimonious, it also yields more information about quantity and allocation performance \citep{pontius2011}. For example, from the table it is straightforward to identify sources of agreement and disagreement considering all land use transitions, all transitions from one land use or a~specific transition from one land use to another. In addition, it is possible to separate agreement between maps due to persistence from agreement due to correctly simulated change. This is important because in most applications the quantity of change is small compared to the overall study area \citep{pontius2004,vanvliet2011}, giving a~high rate of total agreement which can misrepresent the actual model performance. It is useful to perform pattern validation at multiple resolutions because comparison at the native resolution of the three maps fails to separate minor allocation disagreement, which refers to allocation disagreement at the native resolution that is counted as agreement at a~coarser resolution, and major allocation disagreement, which refers to allocation disagreement at the native resolution and the coarse resolution \citep{pontius2011}. \\

In \textbf{lulcc}, three-dimensional contingency tables at multiple resolutions are represented by the ThreeMapComparison class. Two subclasses of ThreeMapComparison represent two types of information that can be extracted from the tables: AgreementBudget represents sources of agreement and disagreement between the three maps at several resolutions while FigureOfMerit represents figure of merit scores. This measure, which is useful to summarise model performance, is defined as the intersection of observed and simulated change divided by the union of these \citep{pontius2011}, such that a~score of one indicates perfect agreement and a~score of zero indicates no agreement. Plotting functions for ThreeMapComparison, AgreementBudget and FigureOfMerit objects allow the user to visualise model performance. The ordered model output for Plum Island Ecosystems is validated in the following way:
\begin{verbatim}
> ordered.tabs <- ThreeMapComparison(x=ordered.model, 
                                     factors=2^(1:8), 
                                     timestep=14) 
> ordered.agr  <- AgreementBudget(x=ordered.tabs) 
> plot(ordered.agr, from=1, to=2) 
> ordered.fom  <- FigureOfMerit(x=ordered.tabs) 
> plot(ordered.fom, from=1, to=2) 
\end{verbatim}
\noindent This procedure was repeated for the CLUE-S model output. The agreement budgets for the transition from Forest to Built for the two allocation procedures are shown by Figure~\ref{fig:agreement}, while Figure~\ref{fig:fom} shows the corresponding figure of merit scores. \\

\section{Discussion}

The example application for Plum Island Ecosystems demonstrates the key strengths of the \textbf{lulcc} package. Firstly, it allows the entire modelling procedure to be carried out in the same environment, reducing the likelihood of mistakes that commonly arise when data and models are transferred between different software programs. A~framework in R specifically allows users to take advantage of a~wide range of statistical and machine learning techniques for predictive modelling. The framework allows users to experiment with various model structures interactively and provides methods to quickly compare model outputs. The example also highlights the advantages of an object-oriented approach: land use change modelling involves several stages and without dedicated classes for the associated data it would be difficult to keep track of the intermediate model inputs and outputs. \\

\textbf{lulcc} is substantially different from alternative environmental modelling frameworks. Most importantly, \textbf{lulcc} is designed for land use change modelling only, whereas frameworks such as PCRaster and TerraME provide general tools that can be applied to various spatial analysis problems such as land use change, hydrology and ecology. As a~result, these tools are targeted towards the model developer rather than the end user. In contrast, most software programs for land use change modelling are designed with the user in mind, with very few providing any way for users or developers to improve or even understand model implementations. With \textbf{lulcc} we have attempted to reduce the gap between user and developer. The R system is well suited for this task, as \citet{pebesma2012} notes ``the step from being a~user to becoming a~developer is small with R". The package system ensures that \textbf{lulcc} will work across Windows, MacOS and Unix platforms, whereas many existing applications are platform dependent. Comprehensive documentation of the functions, classes and methods of \textbf{lulcc}, together with complete working examples, enable the user to immediately start using the software, while the object-oriented design ensures that developers can easily write extensions to the package. \\

Despite its manifest advantages, there remain some drawbacks to land use change modelling in R. Firstly, the lack of a~spatio-temporal database backend to support larger datasets \citep{gebbert2014} restricts the amount of data that can be used in a~given application because R loads all data into memory. The \textbf{raster} package overcomes this limitation by storing raster files on disk and processing data in chunks \citep{hijmans2014}. \textbf{lulcc} has been designed to make use of this facility where possible, however, during allocation it is necessary to load the values of several maps into the R workspace at once because the allocation procedure must consider every cell eligible for change simultaneously. The generic \texttt{predict} function belonging to the \textbf{raster} package offers one possible solution to this problem, allowing predictive models to be used in a~memory-safe way. In effect, this would mean spatially explicit input data including observed land use maps and explanatory variables could be handled in chunks and only the resulting probability surface would have to be loaded into the R workspace. However, this is not currently implemented in \textbf{lulcc} because it is excessively time consuming compared to the current approach. Despite this limitation, since most applications involve a~relatively small geographic extent or, in the case of regional studies \citep[e.g.][]{verburg2009,fuchs2015}, use a~coarser map resolution, memory should not normally cause \textbf{lulcc} applications to fail. For example, the CluesModel and OrderedModel objects from the above example each had a~size of approximately 40Mb, which is easily handled by modern personal computers. On a~64-bit machine with Intel Core i3 @ 1.4 GHz and 4Gb RAM, the allocation methods for the two Model objects took 50 seconds and 8 seconds, respectively. \\

The software presented here is still in its infancy and there are several areas for improvement. The present allocation routines receive the quantity of land use change for each time point before the allocation procedure begins. However, some recent models do not impose the quantity of change but instead allow change to occur stochastically based on land use suitability. For example, StocModLcc \citep{rosa2013} deforests a~cell if the probability of deforestation is less than a~random number from a~uniform distribution. The quantity of change is simply the number of cells deforested after each cell in the study region is considered for deforestation twice, with the probability of change, which depends on the allocation of previous deforestation events, updated after the first round. One advantage of this approach is that it accounts for uncertainty in the quantity and allocation of change simultaneously, whereas the current routines in \textbf{lulcc} only consider the allocation of change as a~stochastic process. Other models such as LandSHIFT \citep{schaldach2011} receive demand at the national or regional level from integrated assessment models such as IMAGE \citep{stehfast2014} or Nexus Land-Use \citep{souty2012}. Coupling \textbf{lulcc} with this class of model would be a~valuable addition to the software because land use change is increasingly recognised as an issue with drivers and implications at local, regional, continental and global levels. \\

An important contribution of \textbf{lulcc} is to provide modules to assist with model pattern validation, a~crucial aspect of model development that is nevertheless frequently overlooked within the land use change modelling community \citep{rosa2014}. A~further improvement that could be made to the package is to incorporate more sophisticated ways of fitting and testing the predictive models that estimate land use suitability. For example, a~routine to calculate the Total Operating Characteristic (TOC) \citep{pontius2014} would improve upon the ROC analysis currently supported. While ROC shows two ratios, hits/(hits+misses) and false alarms/(false alarms+correct rejections), at multiple resolutions, TOC reveals the quantities used to calculate these ratios, allowing greater interpretation of model diagnostic ability. \\

One of the main strengths of \textbf{lulcc} is that multiple model structures can be explored within the same environment. Thus, the more allocation routines available in the package the more useful it becomes. Two existing land use change models, StocModLCC and SIMLANDER, are written in R and available as open source software. Future work could integrate these routines with \textbf{lulcc} to broaden the available model structures and, therefore, improve the ability of \textbf{lulcc} to capture model structural uncertainty. The methods in the current version of \textbf{lulcc} only permit an inductive approach to land use change modelling. Deductive models are fundamentally different because they attempt to model explicitly the processes that drive land use change \citep{perez-vega2012}. This means that, unlike inductive models, they can be used to establish causality between land use change and its driving factors \citep{overmars2007}. Including this class of model in \textbf{lulcc} would allow inductive and deductive land use change models with different spatial resolutions to be dynamically coupled in order to better capture the complexity of the land use system \citep{moreira2009}. \\

Free and open source software improves the reproducibility of scientific results and allows users to adapt and extend code for their own purposes. Thus, we encourage the land use change community to participate in the future development of \textbf{lulcc}. Perhaps one of the simplest ways to improve the package is to experiment with the example datasets to identify bugs and areas for improvement. Those with more programming experience may wish to extend the functionality of the package themselves and contribute these changes upstream. In addition, existing land use change models can easily be included in the package by wrapping the original source code in R; a~relatively straightforward task for commonly used compiled languages (C/C++, Fortran). Users may also develop their own R packages that depend on \textbf{lulcc} for some functionality: this is one of the strengths of the R package system. Finally, we invite land use change modellers to submit land use change datasets (observed and, if possible, modelled land use maps and spatially explicit explanatory variables) for inclusion in the package. \\

%% \conclusions
\section{Conclusion}
In this paper we have presented \textbf{lulcc}, a~free and open source software package providing an object-oriented framework for land use change modelling in R. \textbf{lulcc} allows various aspects of the modelling process to be performed within the same environment, supports three types of predictive model and includes two allocation routines. The modelling process can be expressed programmatically, facilitating reproducible science. Releasing the software under an open source licence (GPL) means that users have access to the algorithms they implement when they run a~particular model. As a~result, they can identify improvements to the code and, under the terms of the licence, are free to redistribute changes to the wider community. We view \textbf{lulcc} as an initial step towards an open paradigm for land use change modelling and hope, therefore, that the community will participate in its development. \\

\section*{Code availability}
The R project for statistical computing is available for Windows, MacOS and several Unix platforms. To download R, visit the project homepage: \url{https://www.r-project.org/}. Two popular and free integrated development environments (IDEs) are provided by RStudio (\url{https://www.rstudio.com/}) and ESS (\url{http://ess.r-project.org/}). We suggest that potential \textbf{lulcc} users familiarise themselves with the \textbf{raster} package by reading the ``Introduction to the raster package" vignette, available on the package homepage: \url{https://cran.r-project.org/web/packages/raster/}. \\

The \textbf{lulcc} source code currently resides on CRAN. This paper corresponds to version 1.0 of the package. It can be downloaded from the R command line as follows:
\begin{verbatim}
> install.packages("lulcc")
\end{verbatim}
\noindent The script for the Plum Island Ecosystems application is available as a~demo within the package. To load the package and run the demo, type the following commands:
\begin{verbatim}
> library(lulcc)
> demo(package = "lulcc")
> demo(topic = "gmd-paper")
\end{verbatim}

\begin{figure}[t]
  \includegraphics[width=8.3cm]{figs/f01_flowchart.pdf}
  \caption{Diagram showing the general methodology used for inductive land use change modelling applications, adapted from \citet{mas2014}. The input land use/land cover data can be a~single categorical map showing the pattern of land use/land cover at one time point (LULC (t1)) or a~series of maps showing historical land use/land cover transitions (LULCC (t1-t0)).}
  \label{fig:flowchart}
\end{figure}

\begin{figure}[t]
  \includegraphics[width=12cm]{figs/f02_class_diagram_revised.pdf}
  \caption{Class diagram in the Unified Modeling Language (UML) for \textbf{lulcc}, showing the main classes and methods included in the package.}
  \label{fig:classdiagram}
\end{figure}

\begin{table*}[t]
\caption{Functions included in the \textbf{lulcc} package}
\begin{tabular}{ p{3.5cm} p{8.5cm} }
%% \tophline
\hline
Function name & Description \\
%% \middlehline
\hline
AgreementBudget    & Calculate agreement budget \citep{pontius2011} \\
getPredictiveModelInputData & Create data.frame with variables required to fit predictive models \\
allocate           & Perform spatial allocation using various methods \\
approxExtrapDemand & Create a~demand scenario by linear extrapolation \\
compareAUC         & Compare the area under the curve (AUC) for various predictive models \\
crossTabulate      & Calculate the contingency table for two categorical raster maps \\
FigureOfMerit      & Calculate the figure of merit \citep{pontius2011} \\
glmModels          & Fit multiple glm models \\
NeighbRasterStack  & Calculate neighbourhood values \\
partition          & Partition Raster* map \\
PredictionList     & Create a~ROCR prediction object for each model in a~PredictiveModelList object \\
PerformanceList    & Create a~ROCR performance object for each prediction object contained in a~PredictionList object \\
predict            & Make predictions using a~PredictiveModelList object \\
randomForestModels & Fit multiple random forest models \\
rpartModels        & Fit multiple recursive partitioning and regression tree models \\
resample           & Resample an ExpVarRasterList object to the parameters of an ObsLulcRasterStack object \\
ThreeMapComparison & Calculate three-dimensional contingency tables \citep{pontius2011} \\
total              & Sum the total number of cells belonging to each class of a~categorical raster map \\
%% \bottomhline
\hline
\end{tabular}
\label{table:functions}
%% \belowtable{}
\end{table*}

\begin{figure}[h]
  \includegraphics[width=12cm]{figs/f03_pie.pdf}
  \caption{Observed land use maps for the Plum Island Ecosystems site in 1985, 1991 and 1999, created by plotting the ObsLulcRasterStack object representing the data.}
  \label{fig:pie}
\end{figure}

\begin{figure*}[t]
  \includegraphics[width=12cm]{figs/f04_suitability.pdf}
  \caption{Suitability of pixels in the Plum Island Ecosystems study site to belong to Forest, Built and Other land use classes according to binary logistic regression models. Elevation and slope are used as explanatory variables for all land uses while Built additionally includes distance to built pixels in 1985.}
  \label{fig:suitability}
\end{figure*}

\begin{figure}[t]
  \includegraphics[width=12cm]{figs/f05_roc.pdf}
  \caption{ROC curves showing the ability of each type of predictive model to simulate the observed pattern of land use in the Plum Island Ecosystems site in 1985 in the data partition left out of the fitting procedure.}
  \label{fig:roc}
\end{figure}

\begin{figure}[t]
  \includegraphics[width=8.3cm]{figs/f06_builtgain.pdf}
  \caption{ROC curve showing the ability of the binary logistic regression model fitted on observed land use data from 1985 to predict the gain in Built land between 1985 and 1991.}
  \label{fig:builtgain}
\end{figure}

\begin{figure}[t]
  \includegraphics[width=12cm]{figs/f07_agreement.pdf}
  \caption{Agreement budget for the transition from Forest to Built for the two model outputs considering reference maps at 1985 and 1999 and simulated map for 1999. The plot shows the amount of correctly allocated change increases as the map resolution coarsens.}
  \label{fig:agreement}
\end{figure}

\begin{figure}[t]
  \includegraphics[width=12cm]{figs/f08_figure_of_merit.pdf}
  \caption{Figure of merit scores corresponding to the agreement budgets depicted in Figure ~\ref{fig:agreement}.}
  \label{fig:fom}
\end{figure}

%% \section{Literature review}

%% \subsection{Land use change modelling}

%% A time series dataset of land cover maps for northern India is essential to assess the impact of land use change on regional water resources and climate. However, given the limitations of supervised and unsupervised classification methods, discussed previously, and the poor quality and availability of satellite images before the launch of NASA's Terra and Aqua satellites, the dataset should be produced using alternative methods. Land use change models are widely used to gain insight into the drivers of land use change and make projections of future land cover change under different scenarios \citep{Veldkamp2001}. Such modelling efforts are frequently used to support land use planning and environmental management \citep{Verburg2002}. However, they may also be used to extrapolate land cover back in time in order to increase the temporal extent of existing land use and land cover maps \citep{Verburg2002}. This method is particularly suited to regions where non spatial census data on the relative area of different land use and land cover types can be used to constrain the model. \\ 

%% The Change in Land Use and its Effects (CLUE) modelling framework \citep{Veldkamp1996} was originally designed to work at a coarse resolution on the national scale. The model works by relating observed land cover to spatially explicit biophysical and socioeconomic driving factors through a statistical model. Biophysical drivers include the suitability of land for different land use types in terms of climate, soil type and elevation, amongst others. Socioeconomic drivers include factors such as population, economic and technological development and political structure. The CLUE-s model \citep{Verburg2004,Verburg2002} extended the CLUE model for regional scales. The key difference between the two models is the spatial resolutions at which they operate \citep{Verburg2002}. Whereas applications of the CLUE model \citep[e.g.][]{Veldkamp1996,Verburg1999} typically relied on census data for model inputs, restricting the spatial resolution to the size of the smallest administrative unit for which data was available, the CLUE-s model is designed to utilise remotely sensed datasets with a finer spatial resolution. \\

%% The CLUE-s model is divided into a non spatial demand module, which specifies the total area of each land cover type at each time step, and a spatially explicit allocation module which allocates land cover change spatially according to the driving factors \citep{Verburg2002}. The basis of the allocation module is a logit model which defines for each grid cell the probability that it is filled with a certain land cover type given a set of driving factors. The logit model can be expressed as:

%% \begin{equation} \label{eq:logit}
%% Log\left(\frac{p_{i}}{1-p_{i}}\right) = \beta_{0} + \beta_{1} X_{1,i} + \beta_{2} X_{2,i} + ... + \beta_{n} X_{n,i}
%% \end{equation} 

%% \noindent where $ p_{i} $ is the probability that grid cell $ i $ contains the considered land cover type and $ X_{1,i} $, $ X_{2,i} $, ..., $ X_{n,i} $ are driving factors. The value of the regression coefficients, $ \beta_{0} $, $ \beta_{1} $, $ \beta_{2} $, $ ... $, $ \beta_{n} $, are determined by fitting the model to observed land use in a stepwise procedure whereby factors that have insignificant explanatory power are excluded from the final model equation. The goodness of fit to the observed data is assesed using the receiver operator characteristic \citep{Pontius2001} which compares the predicted probabiities against the observed land cover for different threshold values covering the full range of predicted probabilities. The CLUE-s methodology is shown by Figure \ref{fig:allocation}. \\

%% \setlength{\floatsep}{1pt}
%% \begin{figure}
%% \centering
%% \includegraphics[width=0.8\textwidth]{figs//clues_allocation}
%% \caption[CLUE-s allocation procedure]{Diagram showing CLUE-s allocation procedure \citep{Verburg2002}}
%% \label{fig:allocation}
%% \end{figure}




\chapter{Land cover change in India}

The lack of an historical land cover change dataset for India... This chapter describes efforts to generate historical land cover data using land use change modelling. \\

\section{Literature review}

\section{Mapping land cover}

Land cover affects the surface energy and water balances by changing the surface albedo and the partition between sensible and latent heat \citep{Sellers1997,Feddema2005}. This means that an accurate description of land cover at the Earth's surface is required to model land-atmospere interactions \citep{Friedl2002}. Additionally, over the last century population growth and technological development has driven rapid and widespread environmental change as human dependence on goods and services from the Earth's ecosystems has increased \citep{Vitousek1997}. Land cover change may be a significant driver of observed changes in regional climate in northern India \citep[e.g.][]{Goswami2006,Pitman2009,Niyogi2010}. However, a land cover change dataset for northern India, documenting the effects of the green revolution in a spatially explicit way, does not exist. In this section the various global land cover products are reviewed, followed by a description of a land use change model, the Change in Land Use and Effects at small regional extent (CLUE-s) \citep{Verburg2002,Verburg2004}, which can be used to extrapolate available land cover products in time. \\

\subsection{Global land cover products}

Early global and regional land cover maps \citep{Olson1983,Matthews1983,Wilson1985} were based on field surveys and ancillary information from different sources. While these efforts provided useful information on global land cover distribution, the maps had low spatial resolution and only provided estimates of potential vegetation based on local climate \citep{Friedl2002}. It is now widely acknowledged that adequate parameterisation of the land surface can only be achieved by assimilating remotely sensed data \citep{Sellers1997,Friedl2002}. Land cover maps based on remote sensing are commonly produced using unsupervised or supervised classification algorithms to divide multispectral satellite images into classes with statistically similar spectral properties \citep{Nemani1997}. Unsupervised classification methods seperate the image into a specified number of classes based on the image statistics. These abstract classes are then assigned to land cover types based on ground truth data. Supervised classification methods divide the image into meaningful classes based on image statistics derived from user identified training samples \citep{Neteler2008}. \\

Several global land cover products have been derived from remotely sensed data \citep{Herold2008}. \citet{Defries1994} produced a map with eleven land cover classes from multitemporal normalised difference vegetation index (NDVI) data at one degree resolution derived from NASA's Advanced Very High Resolution Radiometer (AVHRR) instrument. Land cover types were separated using a supervised classification procedure based on the phenology of different plants reflected in the NDVI data. \citet{Defries1998} extended this method to incorporate  information from all AVHRR spectral bands. \citet{Loveland2000} developed the DISCover product for International Geosphere-Biosphere Project, Data and Information Systems (IGBP-DIS), a map with a spatial resolution of one kilometre produced using unsupervised classification of monthly composited NDVI AVHRR data. Using the same AVHRR dataset, \citet{Hansen2000} created the the University of Maryland (UMD) global land cover product using a supervised classification procedure based on empirical metrics derived from multitemporal AVHRR data. Although AVHRR data has been widely used for global land cover mapping the design of the instrument is not optimised for this purpose \citep{Friedl2002}. It is widely recognised that AVHRR data is sensitive to the effects of clouds, humidity and aerosols \citep[e.g.][]{Nemani1997,Loveland2000,Friedl2002}. Further, \citet{Friedl2000} argues that the poor spectral resolution of the AVHRR instrument makes it unsuitable for land cover mapping applications. Finally, AVHRR data contains a substantial amount of noise because the viewing angle of the instrument varies significantly \citep{Cihlar1994,Friedl2002}. \\

The MODIS instrument, launched on board the NASA Terra satellite in 1999 and Aqua satellite in 2002, was designed to address many of the shortcomings of the AVHRR instrument to provide an improved dataset for remote sensing applitcations \citep{Friedl2002}. The MODIS global land cover product (MOD12) \citep{Friedl2002}, consisting of a 500m spatial resolution land cover map for each year since 2001, is produced using a supervised classification procedure that exploits the information content of seven spectral bands \citep{Friedl2002}. An advantage of the MODIS product over alternative products is that is provides a time series dataset which allows land cover changet to be monitored. However, \citet{Friedl2010} state that inconsistencies in the MODIS dataset, arising from the fact that global land cover is highly dynamic, mean that the change between years indicated by MOD12 is well above observed change. \citet{Thenkabail2005}, as part of the Global Irrigated Area Mapping (GIAM) project of the International Water Management Institute (IMWI) \citep[e.g.][]{Thenkabail2009a}, developed a land cover map of the Indus Ganges basins for 2001 and 2002 at 500m spatial resolution by performing a supervised classification of multitemporal MODIS images with seven spectral bands. This product provides detailed information about the crop calender and irrigation practices in the Indus-Ganges basin. Regional and global land cover maps produced for one point in time, or with low temporal resolution such as the MODIS land cover product, have limited use for land surface modelling applications because they cannot provide information on land cover dynamics on an intraseasonal basis. \\

Regional and global land cover mapping projects using supervised and unsupervised methods, such as those outlined above, require extensive ground truth data to extract meaningful classes from satellite imagery and to formally assess the accuracy of the land cover product \citep{Nemani1997,Loveland2000,Cihlar2000}. Collecting sufficient data for these tasks is time consuming and expensive \citep{Thenkabail2005}. Furthermore, given that land cover is highly dynamic \citep{Foody2002}, it is difficult to ensure the validity of ground truth data after a certain period of time \citep{Friedl2002}. For these reasons it is common to use high resolution satellite imagery and aerial photography as ground truth data \citep[e.g.][]{Defries1998,Loveland2000,Gong2013}, increasing the level of subjectivity required to assign land cover classes to ground truth sites. Performing the classification is again time consuming and highly subjective as the process cannot currently be automated \citep{Loveland2000}. Underlying these issues is the problem of data availability, which is poor for many regions. For many applications, therefore, unsupervised and supervised methods based on statistical classification algorithms are not suitable. \\

Adopting a simple approach, \citet{Running1995} developed a classification logic based on threshold values to distinguish six vegetation classes using multitemporal NDVI data to describe the vegetation canopy. \citet{Lambin1995} showed that class separability improved when classification was performed on the ratio between land surface temperature (LST), which can be detected with remote sensing, and NDVI compared to either dataset taken independently. \citet{Lambin1996} explained in biophysical terms the significance of the LST-NDVI ratio, concluding that whilst the NDVI is an indicator of the vegetation canopy only, LST contains more information about the physical characteristics of the land surface, such as surface roughness and albedo. \citet{Nemani1997} incorporated multitemporal LST, Red and NIR to extend the classification logic put forward by \citet{Running1995} to identify eight vegetation classes. As this method is based on the physical properties of the land surface it is objective and, depending on the quality of the satellite imagery, consistent. It is straightforward to automate the procedure which increases the reproducibility of the method and reduces the time and resources required to produce a land cover product. The main limitation of the method is the limited number of land cover classes it yields. However, implementing such a method may give a first order estimate of the temporal dynamics of the main land cover types across a region. \\




\chapter{India irrigation}

While spatially explicit information about land cover... \\





\chapter{Hydrometeorological feedbacks in Northern India}

This chapter describes the methodology to construct... \\

\newpage
\section{Literature review}

\subsection{Surface energy and water balances}

\subsubsection{Surface energy balance}

Fundamentally, the global climate system is driven by solar radiation, which almost all exists in the shortwave range \citep{Barry2010}. Incoming radiation may be absorbed, reflected or transmitted by the atmosphere \citep{Pitman2003,Seneviratne2010,Barry2010}. The energy that reaches that Earth's surface may be absorbed or reflected depending on the surface albedo. The net radiation at the Earth's surface, $ R_{n} $, can be expressed as:

\begin{algneqn} \label{eq:netradiation}
R_{n}\ &= S \downarrow (1 - \alpha) + L \downarrow - L \uparrow
\end{algneqn}

\noindent where $ S \downarrow $ is incoming shortwave radiation, $ \alpha $ is surface albedo, and $ L \downarrow $ and $ L \uparrow $ are incoming and outgoing longwave radiation respectively. Net radiation is transferred to the atmosphere primarily through sensible and latent heat fluxes \citep{Pitman2003}. Sensible heat is the energy transferred from the Earth's surface to the atmosphere by convection and conduction, while latent heat is the energy absorbed or released by the atmosphere when water changes state. To evaporate water, an amount of energy called the latent heat of vapourisation, which varies with temperature, is released by the atmosphere. When water condenses an amount of latent heat corresponding to the latent heat of vapourisation is transferred to the atmosphere \citep{Barry2010}. The partition between sensible and latent heat fluxes is defined as the Bowen ratio, $ B $, which can be written:

\begin{algneqn}
B\ &= \dfrac{\lambda E}{H}
\end{algneqn}

\noindent where $ \lambda E $ is latent heat flux and $ H $ is sensible heat flux. In addition to sensible and latent heat fluxes net radiation drives the flux of heat to the soil and, where biomass is present, chemical energy which is stored in plants during photosynthesis and subsequently released during respiration \citep{Barry2010}. Collectively these terms gives rise to the surface energy budget equation for a surface soil layer, which can be written as:

\begin{algneqn} \label{eq:energybudget}
\dfrac{dH}{dt}\ &= R_{n} - H - \lambda E - G - F
\end{algneqn} 

\noindent where $ dH / dt $ is the total energy flux within the soil layer, $ G $ is soil heat flux and $ F $ is chemical energy storage. As the soil thickness decreases $ dH / dt $ approaches zero and $ G $ represents the heat flux at the land surface \citep{Seneviratne2010}. \\

\subsubsection{Moist static energy}

The total energy in the planetary boundary layer is called moist static energy and comprises sensible and latent heat, supplied from the surface fluxes of energy and moisture, respectively, and potential energy \citep{Eltahir1998,Prive2007a}. It can be writen as:

\begin{algneqn} \label{eq:mse}
MSE\ &= C_{p}T + L_{v}q + gZ
\end{algneqn}

\noindent where $ C_{p} $ is the specific heat capacity at constant pressure, $ T $ is air temperature in Kelvin, $ L_{v} $ is the latent heat of vapourisation, $ q $ is specific humidity, $ g $ is gravitational force and $ Z $ is elevation. The existence of a significant vertical gradient of moist static energy in the planetary boundary layer, such that moist static energy decreases with elevation, drives moist convection which results in local convective storms \citep{Eltahir1998,Neelin2007,Barry2010}. Similarly, a horizontal gradient of moist static energy strengthens large scale thermal circulation from areas of high moist static energy to an areas of low moist static energy \citep{Eltahir1998,Zheng1998}. Together, these two effects play an important role in the formation of the Asian monsoon. \\

\subsubsection{Surface water balance}

Precipitation reaching the Earth's surface may be intercepted by vegetation or it may fall directly to the soil surface. Intercepted water either evaporates directly from the canopy or falls to the soil surface, where it may enter the soil as infiltration or contribute to surface runoff. Water entering the soil may be evaporated from the surface, drain through the soil to recharge the underlying aquifer or drawn up by plant roots and transpired from the canopy \citep{Pitman2003}. Thus, for the same soil layer considered previously, the surface water budget equation may be written:

\begin{algneqn} \label{eq:waterbudget}
\dfrac{dS}{dt}\ &= P - E - Q_{s} - Q_{d}
\end{algneqn}

\noindent where $ dS/dt $ is the change in storage within the soil layer $ P $ is precipitation, $ E $ is evaporation, $ Q_{s} $ is surface runoff and $ Q_{d} $ is subsurface drainage. It should be noted that Equations \ref{eq:energybudget} and \ref{eq:waterbudget} are linked through the evaporation term. \\

\subsection{Soil moisture feedbacks}

Soil moisture is defined as the water stored in the unsaturated zone of a soil layer \citep{Hillel1998}. Volumetric soil moisture, $ \theta $, defines the volume of water, $ V_{w} $, compared to the total volume, $ V_{t} $, of the soil layer. It can be expressed as: 

\begin{algneqn} \label{eq:volumetric_sm}
\theta\ &= \dfrac{V_{w}}{V_{t}}
\end{algneqn}

\noindent where $ V_{t} $ is comprised of the volume of solids, $ V_{s} $, volume of air, $ V_{a} $ and volume of water. The soil porosity, $ \phi $, is the theoretical maximum value of volumetric soil moisture \citep{Shaw1994}. However, in practice, the maximum soil moisture content that can be utilised by plants is the difference between the field capacity, $ \theta_{fc} $, defined as the maximum amount of water that can be held by the soil matrix against the force of gravity, and the permanent wilting point, $ \theta_{wilt} $, defined as the point at which plant roots cannot draw any water from the soil matrix \citep{Shaw1994}. \\
   
Equations \ref{eq:energybudget} and \ref{eq:waterbudget} show that the surface energy and water balances are linked through the evapotranspiration term. A useful concept when considering the relationship between soil moisture and evapotranspiration is the evaporative fraction, $ EF $, expressed as:

\begin{algneqn} \label{eq:evaporativefraction}
EF\ &= \dfrac{\lambda E}{R_{n}}
\end{algneqn}

\noindent As shown in Figure \ref{fig:evapfraction}, the evaporative fraction increases with soil moisture until it reaches its maximum value, $ EF_{max} $, corresponding to a critical soil moisture value, $ \theta_{crit} $, which lies between the permanent wilting point, $ \theta_{wilt} $, and field capacity, $ \theta_{fc} $ \citep{Seneviratne2010}. For soil moisture values above $ \theta_{crit} $ evapotranspiration is energy limited, while for values less than $ \theta_{crit} $ evapotranspiration is soil moisture limited. When soil moisture falls below $ \theta_{wp} $ evapotranspiration cannot take place. This gives rise to a transitional zone, $ \theta_{wilt} \leq \theta \leq \theta_{crit} $, where soil moisture directly constrains evapotranspiration and, therefore, provides feedbacks to the atmosphere through its impact on the partition between sensible and latent heat \citep{Pitman2003,Seneviratne2010}. \\

\begin{figure}[h]
    \centering
    \includegraphics{figs//evapfraction}
    \caption[Conceptual diagram of different evapotranspiration regimes]{Conceptual diagram showing soil moisture and energy limited evapotranspiration regimes \citep{Seneviratne2010}}.
    \label{fig:evapfraction}
\end{figure}

In addition to its effect on the Bowen ratio, soil moisture lowers the surface albedo which increases the fraction of solar radiation absorbed by the Earth's surface. In transitional regimes these two effects may influence near surface air temperature and precipitation patterns \citep{Seneviratne2010}, illustrated by Figure \ref{fig:feedbacks}. When the latent heat flux at the Earth's surface is limited by soil moisture more energy is available for sensible heating, causing the air temperature to rise \citep{Seneviratne2010}. This has been observed in several locations including North and South America \citep[e.g.][]{Clark2005}, India \citep[e.g.][]{Roy2007} and Europe \citep[e.g.][]{Seneviratne2006}. The relationship between soil moisture and rainfall, which will be the focus of this study, is more complex. Early studies investigated whether the proportion of rainfall supplied by regional evapotranspiration increased with soil moisture \citep[e.g.][]{Eltahir1996,Trenberth1999}. However, recent work has established that the main impact of soil moisture on precipitation relates to its effect on the stability of the planetary boundary layer \citep[e.g.][]{Eltahir1998,Findell2003a,Findell2003b,Alfieri2008,Lo2013}. Conceptually, more evapotranspiration from the Earth's surface increases moist static energy in the planetary boundary layer, resulting in convective instability which, in turn, leads to increased precipitation by driving local moist convection \citep{Eltahir1998}. This explanation is mainly supported by modelling studies \citep[e.g.][]{Zheng1998,Koster2004,Lo2013}, but some observational evidence exists for the Sahel region in Africa \citep{Taylor2006,Taylor2007}. However, alternative modelling experiements have indicated that under certain conditions dry soils cause greater convective instability than wet soils \citep[e.g.][]{Findell2003,Findell2003b}, highlighting the complexity of the feedback mechanism. The nature of the feedback mechanism between soil moisture and precipitation in northern India will be discussed in greater detail in the following sections. \\

\begin{figure}[h]
\centering
\begin{subfigure}[h]{.5\textwidth}
    \centering
    \includegraphics{figs//sm_temp_feedback}
    \subcaption{Soil moisture-temperature}
    \label{fig:sm_temp_feedback}
\end{subfigure}%
\begin{subfigure}[h]{.5\textwidth}
    \centering
    \includegraphics{figs//sm_precip_feedback}
    \subcaption{Soil moisture-precipitation}
    \label{fig:sm_precip_feedback}
\end{subfigure}
\caption[Soil moisture-atmosphere feedback mechanisms]{Soil moisture-atmosphere feedback mechanisms \citep{Seneviratne2010}}
\label{fig:feedbacks}
\end{figure}

\subsection{Role of vegetation in soil moisture feedbacks}
The biosphere is the main interface between soil moisture and the atmosphere \citep{Lawrence2007a,Dirmeyer2006a}. Consequently, land cover and its temporal dynamics have important effects on the interaction between the two domains \citep{Sellers1997,Pielke2002,Feddema2005}. These may be caused by biogeochemical processes, which alter the chemical composition of the atmosphere by affecting the land surface carbon flux, or biogeophysical processes, which alter the surface energy and water balances by changing the surface albedo and Bowen ratio \citep{Feddema2005}. Surface albedo determines the total energy available at land surface \citep{Meehl1994,Pitman2003}. Forests tend to have an albedo between 0.09 and 0.18, while for cereal crops the value typically lies between 0.18 and 0.25 \citep{Barry2010}. Plant physiology affects the Bowen ratio by influencing the rate of transpiration \citep{Hillel1998}. Canopy structure provides a further control on Bowen ratio through its effect on interception and bare soil evaporation, as well as influencing surface roughness, which affects the transfer of momentum from the surface to the atmosphere \citep{Bounoua2002,Arneth2012}. Irrigation, a secondary effect of land cover change, affects the surface water balance and, therefore, alters the Bowen ratio \citep{Boucher2004}. It may also affect the surface albedo both directly, by increasing the amount of water land surface, and indirectly, by altering the physical characterisitics and seasonal dynamics of crops \citep{Seneviratne2010}. \\

\subsection{Assessing the impact of the land surface on the South Asian monsoon}
Early modelling experiments by \citet{Meehl1994} used six atmospheric general circulation models (AGCMs) to investigate the impact of the land surface of continental India on the mean strength of the Asian monsoon. The models consistently associated strong monsoons with positive soil moisture anomolies and higher land surface temperatures, confiming the results of previous global and regional sensitivity studies investigating the impact of soil moisture \citep{Walker1977,Shukla1982,Sud1985} and surface albedo \citep{Charney1977,Sud1985} on precipitation. Limitations of these early modelling experiments include the coarse spatial resolution and the simplistic representation of the land surface used by the AGCMs. First generation land surface models, such as those used by \citet{Meehl1994}, use a simplistic conceptual bucket model to represent soil moisture that cannot adequately represent the complexity of the soil system. Furthermore, since these models do not include a physically based representation of plants, the biophysical control on surface albedo, momentum transfer and evapotranspiration is neglected \citep{Sellers1997}. Nevertheless, based on the modelling results \citet{Meehl1994} hypothesised that strong rainfall in the early stage of the monsoon could initiate a positive soil moisture feedback loop that would sustain rainfall throughout the middle and late stages even when the large scale temperature gradient between the land and the ocean, the fundamental mechanism driving the formation of the monsoon \citep{Turner2012}, decreased. \\

Several studies of GLACE \citep{Koster2004,Koster2006,Guo2006}, based on an ensemble of twelve atmospheric general circulation models, identified northern India, the Sahel region in Africa and central North America as global "hot spots" of soil moisture-precipitation coupling strength during the boreal summer. In the experiment, each participating AGCM performed three ensembles of 16 simulations of the boreal summer under different conditions to isolate the effect of soil moisture on rainfall within the model. The coupling strength was determined through a diagnostic measure based on the variance of precipitation between simulations \citep{Koster2002}. Results from GLACE show that models with a strong link between soil moisture and the surface energy budget, and between the surface energy budget and precipitation, had more explanatory power than models with weak representations of either of these two components, supporting the hypothesis that interactions between the land and atmosphere are significant. Local moist convection, which is initiated by variations in moist static energy in the planetary boundary layer, was identified as an important process relating soil moisture to rainfall, whereas large scale condensation controlled by variations in the global circulation is less important \citep{Guo2006}. \\

The GLACE experiment demonstrates that while multimodel projects can identify certain basic processes where there is broad model agreement, comparing individual models shows a wide range of sensitivity of climate to soil moisture \citep{Seneviratne2010}. \citet{Guo2006} considered the feedback mechanism in terms of the effect of soil moisture on evapotranspiration and the effect of evapotranspiration on precipitation. This division showed that while some variability could be explained by the range of model sensitivity of convection to evapotranspiration, the most important factor is the different land surface parameterisation schemes within the models, particularly in the way that the relative contribution of tranpiration, bare soil evaporation and canopy interception loss is determined in soil moisture limited evapotranspiration regimes. The Project for Intercomparison of Land surface Parameterisation Schemes (PILPS) \citep[e.g.][]{Henderson1995,Henderson1996} demonstrated that different land surface models forced with the same climatological variables and with identical values of land surface parameters produced markedly different results in terms of the surface energy and water balance \citep{Chen1997}. Results from the Land-Use and Climate, IDentification of robust impacts (LUCID) experiment \citep{Henderson1995,Guo2006,Pitman2009}, which used seven climate models to isolate the effects of land cover change on regional and global precipitation patterns, show that land surface models follow different assumptions about the physical characteristics of land cover and land use types, causing model outputs to differ markedly. \\

\citet{Dirmeyer2006a} draw attention to the difficulty in relating the results of ensemble model comparisons to physical quantities from observed datasets. This is made more difficult by the lack of global observed datasets of model outputs such as soil moisture and evapotranspiration \citep{Betts1996,Dirmeyer2006a,Seneviratne2010}. Moreover, establishing the direction of causality from observed datasets of soil moisture and precipitation is difficult because the impact of precipitation on soil moisture is likely to dominate the relationship between the two variables \citep{Seneviratne2010}. \citet{Wei2008} point out that in some cases soil moisture feedbacks could equally be explained by the internal variability of precipitation, through processes such as the Madden-Julian oscillation \citep{Madden1971,Madden1972}, which is known to be important in the Asian monsoon circulation \citep{Webster1987a,Zhang2005}. Alternatively, an additional variable, such as sea surface temperature, may falsely suggest the existence of strong feedbacks between soil moisture and precipitation by affecting both these variables \citep{Notaro2006,Orlowsky2010}. Several studies investigating soil moisture-precipitation feedbacks over the midwest United States, identified as a global hot spot by GLACE, have failed to provide empirical evidence that soil moisture affects precipitation patterns in this region \citep[e.g.][]{Findell1997,Salvucci2002,Alfieri2008}, highlighting the level of model uncertainty regarding soil moisture-precipitation feedbacks. \\

The lack of agreement between models is particularly problematic for northern India where there is large uncertainty about the direction, magnitude and spatial pattern of future changes to monsoon rainfall \citep{Goswami2006,Turner2009}. \citet{Pitman2009} identified the lack of a common land cover change dataset to force the models as a major contributor to model uncertainty about the impact of historic land cover change on precipitation. In many regions this is exacerbated by the limited availability of remotely sensed observations at sufficient temporal extent and resolution to detect land cover change \citep{Goward2006}. Uncertainty also arises from the different land surface parameterisation schemes implemented by global climate models \citep{Pitman2009}. This problem is made worse by the fact that these models cannot be calibrated to local conditions as land surface state variables evolve in response to model output. This is relevant to northern India where processes such as irrigation, which are not represented in global climate models, are known to be important \citep{Boucher2004,Gordon2005}. To overcome this problem global climate models can be forced with the output of offline, high resolution, physically based hydrological models driven by observed meteorological data and calibrated againsts local observed hydrological data \citep{Seneviratne2010}. Given the scarcity of observed data available for northern India, it is necessary to develop methods that utilise remote sensing data for this purpose. \\

% update this section - see monsoon_litreview.odt

\subsection{Summary}
The green revolution in India has driven substantial environmental change. The revolution has enabled India to become self sufficient in food grains \citep{Singh2000}, however, it has also caused widespread land cover change and a marked increase in the exploitation of water resources \citep{Shah2006,Roy2007,Scott2009}. The pressure on water resources in India is likely to increase with forecasted population growth and continued economic progress. Moreover, climate change may increase the erratic behaviour of the Asian summer monsoon, presenting a significant risk to regional water supply \citep{Goswami2006}. \\

Land cover change and changing irrigation practices may affect the water resources and fluxes in northern India in complex ways. Further, there is evidence of feedbacks between soil moisture and precipitation. Soil moisture, which is strongly influenced by land cover \citep{Dirmeyer2006,Lawrence2007a}, affects the partition of sensible and latent heat and the albedo at the Earth's surface \citep{Meehl1994,Pitman2003,Seneviratne2010}. Conceptually, this may influence precipitation by increasing the moist static energy in the planetary boundary layer, driving local moist convection \citep[e.g.][]{Eltahir1998}. However, the feedback mechanism is complex and some modelling studies have shown that convective instability is stronger over dry soils \citep{Findell2003a,Findell2003b}. Nevertheless, several studies of Global Land-Atmosphere Coupling Experiment (GLACE) \citep{Koster2004,Koster2006,Guo2006}, based on twelve atmospheric general circulation models, identified northern India as a "hot spot" of soil moisture-precipitation coupling strength during the boreal summer. However, while there is broad agreement between the global climate models about the basic feedback mechanism, comparing individual models shows a wide range of sensitivity of climate to soil moisture \citep{Koster2004,Guo2006,Pitman2009}. Consequently there is a lack of understanding about the impact of land cover change on regional water resources and climate. \\ 

In northern India there is large uncertainty about future changes to the Asian summer monsoon \citep{Goswami2006,Turner2009}, which supplies approximately 70\% of regional rainfall \citep{Thenkabail2005}. There is a need, therefore, to improve the ability of models to simulate historical trends in order to reduce the uncertainty associated with future predictions. \citet{Pitman2009} identifies the lack of a common land cover change dataset to force the models as a major contributor to the uncertainty about the impact of historic land cover change on rainfall. While a number of global and regional land cover products are available \citep[e.g.][]{Hansen2000,Loveland2000,Friedl2002}, none provide information about land cover change in northern India over the study period. Land use change models can be used to extrapolate land cover back in time \citep{Verburg2002}. One such model, CLUE-s \citep{Verburg2002,Verburg2004}, simulates the spatial pattern of land cover change based on spatially explicit, static and dynamic driving factors and non-spatial estimates of land cover area. A further source of uncertainty arises from the different land surface schemes implemented by different climate models \citep{Henderson1996,Pitman2009}, which is exacerbated by the fact that these models cannot be calibrated to local conditions. To overcome this problem global climate models can be forced with the output of offline, high resolution, physically based hydrological models, calibrated against local observed data \citep{Seneviratne2010}. However, this has not been attempted for northern India. \\

In this study... \\

\section{Materials and methods}

\subsection{Study region}
The Ganga basin in northern India.

\subsection{JULES}
Description of the JULES land surface model.

\subsection{Input data}

\subsubsection{Land cover}
Historical land cover data... \\

\subsubsection{Meteorological data}
JULES requires precipitation and temperature data...

\subsubsection{Ancillary data}
Soil data from the Harmonised World Soil Database

\subsection{Procedure}
The JULES model was run for the period 1970--2005. Soil moisture was retrieved from the output files... \\

\section{Results}
TODO

\section{Discussion}
TODO

\section{Conclusion}
TODO




%% Facilitating hydrological data analysis workflows in R: the RHydro package (EGU 2015 presentation title)
\chapter{Facilitating workflows in the hydrological sciences}

%% Hydrology is an earth science that studies the distribution and quality of water in time and space \citep{}. 

%% introduce the idea of modelling and broad model categories
Hydrological modelling is often used to inform water resources management decisions... Scientific hydrology is concerned with improving our understanding of hydrological systems. Hydrological models reflect the combined knowledge of the community \citep{}. Modelling itself is a learning process \citep{box1976}

\citet{shao2009} defines a scientific workflow as 'a set of experiments performed in an order that is consistent with certain constraints in order to achieve a scientific goal'. More specifically, in the hydrological sciences a workflow describes data manipulation and modelling required to simulate or forecast a set of output variables.

The advent of new technologies such as distributed computing and the Semantic Web, combined with the ever-expanding volume of environmental data, will change the way that models are built and used \citep{beven2007,salas2012,bastin2012}. Alongside the scientific challenge of designing adequate workflows to answer specific questions is the technical challenge of implementing them efficiently \citep{vitolo?}. Data processing languages, especially R \citep{R2015} and Python, are quickly gaining popularity because they combine a wide array of functionality with high flexibility and versatility. In this paper, we explore how handling and processing of hydrological data in R can be facilitated further by designing and implementing a set of relevant classes and methods in the experimental R package RHydro. \\

%% ...including those related to flood protection and water resources management \citep{sivapalan2003}. Instead, there was a concerted effort to improve scientific understanding of catchment scale hydrological processes \citep{hrachowitz2013}. As a result of the PUB Scientific Decade, there is now... \\

%% ...has led to the development of numerous hydrological models \citep{clark2011,weiler2015}. 
%% There has been much debate about the appropriate type of uncertainty analysis for different applications in hydrological modelling (see debate in \citet{beven2006,beven2008,beven2012-c,beven2012-a,clark2011,clark2012,montanari2007}). 

\newpage
\section{Literature review}

\subsection{Trends in hydrological modelling}

%% To engineers, hydrological models are primarily tools for problem solving and decision making \citep{savenije2009}. To scientists, 

%% Hydrological models represent our perceptual understanding of the way that a system functions \citep{savenije2009,hrachowitz2013}. \\
 %% and, thus, encapsulate the knowledge and understanding of the community \citep{savenije2009}
%% In scientific hydrology models represent hypotheses about the way that the real world functions \citep{savenije2013}. 

Hydrological modelling is fundamental to the hydrological sciences \citep{buytaert2008}. Models provide a representation of the hydrology of a catchment to forecast its response to future conditions or to simulate the behaviour of catchments where no output or state variables are measured \citep{beven2001}. A useful classification scheme for hydrological models proposed by \citet{wheater1993} divides models into empirical, conceptual and process-based models. Empirical models seek to characterise aspects of catchment behaviour from observations of input and output variables \citep{wheater2002,pechlivanidis2011}. Conceptual models consist of simplified representations of the hydrological processes perceived to influence the system response and include parameters that do not correspond with physical quantities and, therefore, must be inferred from observations \citep{kavetski2006}. Process-based models are based on mathematical equations describing physical processes \citep{montanari2012,beven2013-a}. They have variously been referred to as ``physics-based'' or ``physically-based'' models; however, since all models in practice contain simplifications of the actual physics, ``process-based'' is a more precise description of the modelling approach \citep{montanari?}. The IAHS Scientific Decade (2003--2012) Predictions in Ungauged Basins (PUB) was formulated on the basis of concern amongst hydrologists that empirical methods were unable to deal with a range of issues that required predictions of streamflow in ungauged basins or under non-stationary conditions \citep{sivapalan2003}. Thus, over the course of the Scientific Decade there was a concerted effort to improve scientific understanding of catchment scale hydrological processes \citep{hrachowitz2013}. Following the PUB initiative there is consensus in the scientific hydrological community that models should be viewed as hypotheses about system behaviour and that modelling itself is a learning process \citep{hrachowitz2013}. This realisation has led to the proper application of the scientific method of \citet{popper1959} in the hydrological sciences \citep[e.g.][]{buytaert2011}. \\

Hydrological models are associated with a large amount of epistemic uncertainty arising from a lack of knowledge about the appropriate mathematical representation of hydrological processes at different spatial scales, a lack of knowledge about the physical properties and boundary conditions of catchments and a lack of knowledge about the reliability of input and validation datasets \citep{beven1989,beven2012,clark2011,clark2015,gupta2012,mount2016}. While in theory process-based models contain parameters that refer to measurable quantities, in practice models rely on calibrated, ``effective'' parameter values to implicitly account for the spatial heterogeneity of catchment properties and incomplete process understanding \citep{mcdonnell2007,savenije2009,sivakumar2009,beven2012}. Thus, both conceptual and process-based models are calibrated to some degree giving rise to the notion that for a given place various model structures and parameter sets are capable of simulating response variables equally well, known as equifinality \citep{beven2001,beven2006-a,beven2012-b}. Consequently there is a lack of agreement about the appropriate model structure for different applications \citep{}, which has led to the development of numerous hydrological models to address a wide range of scientific and engineering questions \citep{beven2001,clark2011,weiler2015}. \\

The various models accumulated by the hydrological modelling community may be viewed as working hypotheses about the hydrological behaviour of various places \citep{clark2008,savenije2009,clark2011,gupta2014}. To develop better models there is a need to identify the strengths and weaknesses of current models and highlight the processes and systems that are poorly understood in order to drive the collection of new or more accurate data and devise field studies of specific processes \citep{buytaert2008,clark2012,gupta2012}. This is one of the main aims of uncertainty analysis \citep{buytaert2008,clark2012,gupta2012}, and fundamental to the notion of modelling as a learning process. However, while there have been several model intercomparison studies in recent years \citep[e.g.][]{wood1998,yang2000,reed2004,pebesma2005,duan2006,breuer2009,smith2012}, these have largely failed to diagnose differences in model performance because the structure and implementation of different models varies so widely \citep{kampf2007,fenicia2008,clark2011,clark2015}. The problem is made worse by the fact that it is hard to resolve structural errors in calibrated models because of problems arising from equifinality \citep{kirchner2006}. \\ 

%% \citep{clark2011,fenicia2011,euser2013}.
According to \citet{clark2011}, hydrological models should be viewed as a collection of coupled hypotheses about different aspects of the catchment system. These component hypotheses cannot necessarily be tested at the level of the system as a whole because of potentially complex relationships between constituent parts within the model structure that can obfuscate model deficiencies \citep{clark2011,clark2012}. Thus, in order to test, and potentially reject, model structures as hypotheses it is necessary to isolate model components and evaluate them independently as well as in combination with different representations of linked processes \citep{clark2011}. This is challenging because existing models vary substantially in conceptualisation and implementation \citep{castronova2013,clark2015}. The fact that many hydrological models are released as closed source software packages is a fundamental impediment to scientific progress which limits the reproducibility of scientific results and forces modellers to duplicate the work of others \citep{morin2012,steiniger2013,moulds2015}. Consequently model development to date has occurred on an \textit{ad hoc} basis, relying on the efforts of individuals and research groups rather than a systematic effort by the entire hydrological modelling community \citep{buytaert2008,clark2015,troy2015,weiler2015}. A lack of discourse between modellers and field experimentalists means that the current generation of hydrological models fo not reflect advances in process understanding gained from field studies \citep{mcdonnell2007,clark2011}. \\

%% facilitates hypothesis testing of model components and the inclusion of additional and alternative process representations. %% as our perceptual understanding of a system improve.
Recognising these issues, members of the community have started to question whether a new approach to hydrological modelling is required \citep[e.g.][]{sivapalan2009,savenije2009}. In particular there has been a concerted effort to develop flexible modelling frameworks that facilitate the systematic development, evaluation and comparison of multiple model structures as hypotheses of catchment behaviour, and the inclusion of additional and alternative process representations as our perceptual understanding of the system improves. This approach recognises the fact that each catchment is unique and that fixed model structures are incapable of handling natural variability in space and time \citep{beven2000}. In conceptual modelling the Framework for Understanding Structural Errors (FUSE) \citet{clark2008} allows different representations of model components within a fixed model architecture, while SUPERFLEX \citep{fenicia2011,kavetski2011} provides a more flexible approach to model building by allowing various combinations of generic model components. The Structure for Unifying Multiple Modeling Alternatives (SUMMA) \citep{clark2015-b,clark2015-a} aims to provide a unified framework for developing process-based hydrological models. Many of these frameworks are implemented as open source software projects encouraging users of the software to contribute to model development \citep{clark2015-b}. While these frameworks are useful modelling tools in themselves, they may also be used as test-beds for a community hydrological model of the type proposed by \citet{weiler2015} or the next generation of ``hyper-resolution'' land surface models suggested by \citet{wood2011} and debated elsewhere \citep{beven2012,wood2012,nazemi2015}. \\

%% It facilitates the development and comparison of multiple model structures as hypotheses about the functioning of hydrological systems by providing interchangeable model components \citep{clark2015-a}. \\

%% paragraph  4: socio-hydrological modelling: motivation and approach
A recent advance in our perceptual understanding of hydrological systems is the recognition that the water cycle is no longer governed entirely by natural processes but also, increasingly, by anthropogenic activities \citep{montanari2013,savenije2014,sivapalan2015}. This has given rise to the nascent field of socio-hydrology, which is concerned with understanding the feedbacks and interactions between coupled human-water systems in order to improve the resilience and sustainability of these systems under environmental and social change \citep{sivapalan2012}. Its fundamental importance to the wider discipline of hydrology is demonstrated by its central role in defining the current IAHS Scientific Decade (2013-2022), ``Panta Rhei--Everything Flows'' \citep{montanari2013}, which aims to gain new insight into the processes governing the hydrological cycle by concentrating research activities on the interactions between society and the environment \citep{montanari2013,mcmillan2016}. In their introduction to the Scientific Decade, \citet{montanari2013} draw attention to the fact that the current generation of hydrological models have mostly been developed for the analysis of pristine catchments, with human impacts on the environment generally represented through separate models. Socio-hydrological modelling instead treats anthropogenic activities as an integral part of the water cycle rather than an external forcing \citep{troy2015}. It aims to provide insight into the mechanisms and drivers of human-water interactions, support decision-making and policy development and make forecasts and predictions about the response of socio-hydrological systems under future conditions \citep{kelly2013,blair2016}. \\

%% According to \citet{savenije2014}, humans impact the hydrological cycle in four principle ways: (1) exploiting water resources for domestic, industrial and agricultural uses, (2) developing infrastructure that alters the natural characteristics of river networks, (3) altering the properties of catchments through land use change and intensification, and (4) anthropogenic climate change which alters the hydrological cycle.

%% paragraph 5: complexity
Coupled human-water systems are complex systems involving `multiple interacting components, local connections and nonlinear relationships between the components' \citep{troy2015}. Developing models of these systems is challenging for various reasons. Different system components interact at different spatial and temporal scales \citep{elshafei2014}. There is epistemic uncertainty about the relationships between system components, particularly concerning indirect relationships, alongside the aleatory and epistemic uncertainty associated with models of individual system components, including those representing hydrological processes \citep{elshafei2014,dibaldassare2015-a,mount2016}. Furthermore, it requires effective collaboration between diverse research communities in order to include the state-of-the-art in terms of the knowledge and understanding of system components \citep{blair2016}, which is often difficult \citep{montanari2013}. Current socio-hydrological models mainly consist of stylized relationships intended to develop hypotheses about the system and explore its behaviour under different scenarios of social and environmental change \citep[e.g.][]{vanemmerik2014,dibaldassare2015-a,garcia2016}. However, in the future there will be a need to incorporate more realistic models capable of providing insight into socio-hydrological systems rather than simply reinforcing what is already known \citep{troy2015,loucks2015,blair2016}, as well as making predictions about the co-evolution of social and hydrological systems under future conditions \citep{}. This will involve more complete models of human behaviour \citep{loucks2015}, as well as more accurate models of hydrological systems \citep{gober2015,mount2016}. \\

%% Indeed, one of the aims of the current Scientific Decade is to devise models that fully integrate social processes  In such a way that socio-hydrology is not seen as separate to more traditional forms of hydrological modelling but rather an integral part \citep{}.

%% Coupled-component models integrate specialised models of system components to provide a representation of the system as a whole \citep{kelly2013,blair2016}. Thus, separating models into components is desirable to facilitate model building and developing model structures as multiple working hypotheses about the system \citep{troy2015-a}. To date, however, socio-hydrological models have been usually been developed in an \textit{ad hoc} manner as specialist software tools in which the model equations are tightly coupled. Some researchers have released their model implementations alongside publications \citep[e.g.][]{garcia2016}, while others have not. \\

%% The advantage of coupled-component models is that they allow `detailed representations of system components' by exploiting the expertise, manifested in models, of separate research communities \citep{kelly2013}. Component models have usually been validated in the system domain they represent \citep{voinov2013,blair2016}. Furthermore, the process of bringing together expertise from traditionally separate research communities, such as water resources management and social sciences, facilitates transdisciplinary learning \citep{blair2016}. \\

%% The observation made by \citet{clark2011}, that hydrological models should be viewed as a series of coupled hypotheses about the system as well as an overarching hypothesis about how different component relate to each other, is equally true of socio-hydrological modelling \citep{troy2015-a}. 

%% about the correct combination of system components as well as the correct representation of individual system components, especially concerning the representation of behavioural responses to hydrological extremes \citep{troy2015-a,gober2015}.

%% The fact that many hydrological models are released as closed source software packages is a fundamental impediment to scientific progress which limits the reproducibility of scientific results and forces modellers to duplicate the work of others \citep{morin2012,pebesma2012,steiniger2013,moulds2015}. Furthermore, current model implementations are frequently platform dependent, with many hydrological models only available for the Windows operating systems \citep{buytaert2008}. 

%% Nevertheless, the overall trend in hydrological modelling is towards a more systematic, flexible approach to model development that facilitates hypothesis testing of model components and the inclusion of additional and alternative process representations. %% as our perceptual understanding of a system improve.

\subsection{Modelling complex systems}

%% paragraph 1: representing complex systems
Representing complex systems in a single model structure is both challenging and undesirable \citep{beven2007}. Instead, model coupling has emerged as an effective way to build integrated environmental models \citep{goodall2011,bulatewicz2012,yue2014}. However, developing scientific workflows involving coupled models is challenging because different models are implemented in different programming langauges, built for different operating systems and accessed through different types of user interface \citep{buytaert2008,castronova2013,weiler2015,yue2015}. In recent years several tools have been developed to facilitate model coupling based on the notion of component-based frameworks \citet{argent2004}. These tools consist of model components with a standard interface to ensure that different components within the same framework interact correctly \citep{valcke2012}. The need for couplers was first addressed by the climate modelling community to couple separate components of earth system models, resulting in solutions including the Earth Systems Modeling Framework \citep{hill2004}, Ocean Atmosphere Sea Ice Soil (OASIS) \citep{}, and the Community Surface Dynamics Modeling System (CSDMS) \citep{}, which are designed to couple the core components of earth system models. There are few applications of these technologies to hydrological modelling, although \citet{shrestha2014} coupled a land surface model (NCAR Community Land Model version 3.5), a groundwater model (ParFlow) and an atmospheric model (Consortium for Small-Scale Modeling, COSMO \citep{}), using OASIS version 3.0 to create a fully integrated earth system model including groundwater dynamics, which most earth system models ignore \citep{maxwell2005}. Coupling technologies for earth system modelling result in tightly coupled applications in which the source code of the respective model components is ported to a single modelling application \citep{goodall2011}. This approach is computationally efficient and gives modellers the greatest amount of control over the way that processes are represented and data is exchanged in the coupled system \citep{goodall2011,buahin2015}. However, it lacks flexibility because it is difficult or impossible to integrate models that do not comply with specific requirements in terms of programming langauge and model structure \citep{goodall2011,salas2012}. \\

%% paragraph 3
One of the main goals of the Open Modeling Interface (OpenMI) is to promote interoperability between new and existing models \citep{moore2005,gregerson2007,goodall2011}. The coupling framework supports a loose-coupling approach in which model components adopt a standard interface allowing them to exchange data at run time \citep{moore2005}. This gives developers of model components greater freedom to implement model equations in the most efficient way possible, while developers of coupled system models have greater flexibility about the model structure \citep{goodall2011}. In principle, any combination of OpenMI-compliant models can be dynamically coupled \citep{gregerson2007}, although existing applications of the framework are mainly focused on hydrological modelling \citep{}. To adapt an existing model to the OpenMI standard it is necessary to represent the model as a C\# class implementing a set of defined operations \citep{}. This is relatively straightforward if the original model is written in a supported language (.NET, C\#) but considerably more challenging otherwise \citep{}. Another drawback of OpenMI is that it is designed primarily for Windows and support for other operating systems is variable. It has been ported to Linux using the Mono compiler although according to the project website it is only tested on one Linux distribution (OpenSUSE 11.0, 64-bit) and it is unclear whether the development cycle for the Linux version follows that of the main Windows version. Modelling the interactions and feedbacks in coupled human-water systems for sustainable water resources management requires `an integration of models across disciplinary boundaries' \citep{goodall2011}. This is a limitation of frameworks such as OpenMI which have been developed to serve a particular community. \\ 
%% Some more drawbacks?
%% Simple Script Wrapper?

%% paragraph 4
Existing coupling frameworks, including those designed for earth system modelling as well as OpenMI, require the source code of the original models to be substantially modified \citep{voinov2013}. This may be acceptable if the structure of the coupling application is known at the outset and involves a small number of model components. In practice, however, scientific workflows are refined iteratively and may change considerably as hypotheses are rejected and new ones are developed \citep{mcguire2007,dunn2008,fenicia2008,shao2009}. At the same time, given the substantial levels of epistemic uncertainty about the most appropriate model structure to represent hydrological and coupled human-water systems \citep[e.g.][]{dibaldassarre2015-a}, it is necessary to evaluate multiple models as working hypotheses about the functioning of the system \citep{clark2015}. Changing the source code of a large number of models is simply not practicable because it is time consuming, requires a high level of ability in various programming languages and techniques \citep{bulatewicz2012}, and may remove the models from the development cycle \citep{voinov2013}. \\

%% paragraph 5
The concept of the Model Web envisages `a dynamic web of models, integrated with databases and websites, to form a consultative infrastructure where researchers, managers and policy makers and the general public can go to gain insight into ``what if'' questions' \citep{bastin2013,geller2007}. It would enable the integration of resources, including data and models, to build coupled models of complex systems where components are loosely coupled over a distributed system of networked computers \citep{geller2007,goodall2011,bastin2013}. The Model Web is based on a service-oriented architecture in which models and databases are exposed as interoperable Web services \citep{castranova2013,nativi2013,schade2012}. Individual services within a network are regarded as black-boxes and may have no awareness of other services in the network \citep{barbosa2009}. Service orchestration is the coordination and arrangement of multiple services to execute a service-oriented workflow \citep{barbosa2009}. \citet{goodall2011} used the OpenMI Configuration Editor to orchestrate a simple rainfall-runoff model consisting of three components to calculate excess rainfall, incremental runoff and river routing using implementations of the Curve Number method, Unit Hydrograph method and Muskingham Routing method respectively. It was also used by \citet{goodall2013} to coordinate a two-way coupling between the Community Atmosphere Model, implemented within the Earth System Modeling Framework, and the OpenMI-compliant Soil Water Assessment Tool \citep{betrie2011}. The OpenMI Configuration Editor is associated with the disadvantages of OpenMI discussed previously, especially the fact that model components must be OpenMI-compliant. Furthermore it is a desktop application for Windows that would not be appropriate for server-based computing. \\

%% paragraph 6
Scripting langauges provide an alternative approach to service orchestration \citep{ousterhout1998,bu2015}. They are designed primarily for ``gluing'' together various functional components either written in the same language or in system programming languages such as C/C++ and Fortran \citep{ousterhout1998}, provide sophisticated methods for handling and processing data in various forms as well as high-level functionality for accessing Web resources \citep{bu2015}. The R environment for statistical computing \citep{R2015} is a free and open source implementation of the S language \citep{chambers2008}, which compiles and runs on a wide variety of Unix platforms, Windows and MacOS. One of the main strengths of R it its support for extension packages, which are distributed through the Comprehensive R Archive Network (CRAN) and other repositories \citep{pebesma2012}. In this paper we describe a new, experimental R package, RHydro, designed to facilitate the use of R as an orchestration engine for hydrological workflows. The R system is well suited for this purpose as it provides support for handling and manipulating the various data types and formats encountered in hydrology and other disciplines, including several classes for representing time and sophisticated methods for time series analysis as well as dedicated classes and methods for various types of spatial and spatio-temporal data \citep{pebesma2012}. Interfaces to the GDAL and OGR libraries ensures interoperability with most spatial raster and vector file formats and provides transformation between spatial reference systems through the PROJ.4 cartographic projections library. The ability to handle spatial and spatio-temporal data includes going from one representation to another (regridding, aggregation, disaggregation) as well as geostatistical interpolation and stochastic simulation \citep{pebesma2004}. It also contains low-level packages for parsing data from Web services such as \textbf{RCurl} and \textbf{SSOAP}, as well as high-level packages provide access to the CUAHSI WaterOneFlow family of Web services \citep{kadlec2015}, and the Consortium of Universities for the Advancement of Hydrologic Science (CUAHSI) controlled vocabulary \citep{horsburgh2009}. \\

%% Consequently there has been little progress in hydrological modelling compared to disciplines such as ocean and climate modelling where model development is community driven \citep{weiler2015}.

%% Recently, \citet{weiler2015} discussed the need for a community hydrological model to act as a focus for model development activities. \citet{wood2011} argue that the community should instead focus on developing the next generation of ``hyper-resolution'' land surface models as fully-functioning hydrological models. A similar argument was made by \citet{nazemi2015}, who called for water resources management activities to be incorporated with earth system models.

%% \citep[e.g.][]{wood2011,nazemi2015,clark2015-a,weiler2015}.
%% distributed, process-based hydrological models

%% developers make different decisions about model fidelity, complexity and practicality (see \citet{clark2015} for definitions of these terms) as well as data availability,
%% , with the aim of 

%% For example, \citet{dibaldassarre2015-a} developed a socio-hydrological model consisting of five? partial differential equations to simulate the feedbacks between flood risk and society. \citet{garcia2016} produced a model that models feedbacks between water scarcity, water demand and population growth based on four differential equations.

%% As \citet{blair2016} points out, the discipline of socio-hydrology has largely come about from researchers with backgrounds in water resources management and currently lacks input from the social sciences. Modelling complex systems also leads to decisions about the appropriate balance between simplicity and complexity required to achieve model parsimony, the perception of which varies substantially between individuals and communities \citep{}.
%% , considering in particular ``green'' societies, which manage flood risk by moving outside flood plains, and technological societies, which handle flood risk by building structures intended to reduce the frequency of flooding events such as levees and dikes.

%% 

%% \citet{vanemmerik2014} modelled the interaction and feedbacks between water resources management and agricultural water use in the Murrumbidgee River basin in Australia, while 

%% %% TODO: summary paragraph
%% Hydrological modelling faces several important challenges. Substantial uncertainty about the best way to represent physical processes has led to a large number of hydrological models. At the same time hydrological modellers are increasingly asked questions concerning coupled human-water systems.

%% While the first step has received considerable attention in recent years, particularly as a result of the IAHS Scientific Decade Predictions in Ungauged Basins \citep{sivapalan2003}, there has been relatively little progress in transferring... to hydrological models \citep{buytaert2008,gupta2012,hrachowitz2013,weiler2015}. One reason for this is the inability of current model e

%% Where uncertainty estimation can be carried out under the constraints of a single, fixed model structure, it can also address the uncertainty in the particular choice of a model structure by considering multiple models as working hypotheses \citep{buytaert2011,clark2008,clark2011}. 

%% Model coupling has emerged as an effective way to build integrated environmental models \citep{goodall2011,bulatewicz2012}. 
%%  \\ % (\url{https://mgarcia.shinyapps.io/ReservoirOperations/})
%% 

%% Empirical models seek to characterise aspects of the behaviour of a catchment from observations of input and output variables \citep{wheater2002,pechlivanidis2011}, while conceptual models consist of simplified representations of the hydrological processes perceived to influence the system response \citep{wheater2002}. They include parameters that cannot be measured and, therefore, must be inferred from observations \citep{kavetski2006}. Process-based models are based on mathematical equations describing physical processes with parameter values that can, in principle, be measured \citep{montanari2012,beven2013-a}. [TODO: discussion of sources of epistemic uncertainty] ...has led to the development of numerous hydrological models \citep{clark2011,weiler2015}. 

%% \subsection{Socio-hydrological modelling}

%% Progress in scientific hydrology is further impeded by current modelling practice \citep{buytaert2008}. Efficient model development strongly depends on the availability of models as free and open source software \citep{morin2012,pebesma2012,steiniger2013,moulds2015}. The fact that many hydrological models are released as closed-source software packages is a fundamental impediment to scientific progress. Even if models are perfectly described it is impossible to guarantee the reproducibility of model results unless the implementation details, including the model source code, is freely available \citep{ince2012}. Moreover, it forces the duplication of work \citep{}. Current model implementations are frequently platform dependent, with many hydrological models only available for certain operating systems, often Windows \citep{buytaert2008}. This makes it harder to compare different models, particularly in the context of models as working hypotheses \citep{clark2011}. \\

%% The fact that some models are released as closed-source software packages makes it virtually impossible to test component hypotheses \citep{ince2012}, while other models only work on specific operating systems. Considering all these factors it is often difficult to isolate specific process representations in different models so that hypotheses can be tested properly \citep{clark2011}. \\ 
%% From the point of view of model development closed source software packages are effectively black boxes with no way of knowing model implementation details. 
%% Where uncertainty estimation can be carried out under the constraints of a single, fixed model structure, it can also address the uncertainty in the particular choice of a model structure by considering multiple models as working hypotheses \citep{buytaert2011,clark2008,clark2011}.
%% It is noteworthy that land surface models, increasingly used in hydrology despite considerable shortcomings \citep{beven2012,clark2015},

%% discrete/continuous events?
%% particularly under non-stationary conditions 
%% discuss deterministic vs stochastic, spatially lumped vs. distributed
%% see \citet{blair2016} and other reviews

%% Uncertainty analysis is used to identify sources of error and uncertainty within a modelling application \citep{buytaert2008}. Various techniques are used, ranging from the Generalised Likelihood Uncertainty Estimation (GLUE) framework \citep{beven1992,liu2007}, based on the subjective assessment of whether a model is `behavioural' (consistent with observations) or `non-behavioural', to formal statistical frameworks in which uncertainty is treated as a probabilistic variable.\\

%% Hydrological modelling is subject to a large amount of uncertainty from various sources. According to \citet{beven2013-a}, the two main types of uncertainty encountered in hydrology area aleatory uncertainty and epistemic uncertainty. Aleatory uncertainty arises from random variability present in the system and cannot be reduced by gaining additional knowledge or understanding \citep{koutsoyiannis2010,montanari2012,beven2013-a}. Epistemic uncertainty is the result of a lack of knowledge about the appropriate model structure and parameter set to adequately represent a hydrological system or about the input data and response data used to evaluate model performance \citep{beven2015}. 

%% There has been much debate about the appropriate type of uncertainty analysis for different applications in hydrological modelling (see discussion in \citet{beven2006,beven2008,beven2012-c,beven2012-a,clark2011,clark2012,montanari2007}). However, regardless of the approach taken, there should be two main consequences of uncertainty analysis \citep{buytaert2008}. Firstly, it should identify processes and systems that are poorly understood and, consequently, drive the collection of new or more accurate data and the study of specific processes. This is fundamental to the view of modelling as a learning process \citep{juston2013}. Where uncertainty estimation can be carried out under the constraints of a single, fixed model structure, it can also address the uncertainty in the particular choice of a model structure by considering multiple models as working hypotheses \citep{buytaert2011,clark2008,clark2011}. 

%% The second outcome should be to translate knowledge to the model software. While the first step has received considerable attention in recent years, particularly as a result of the PUB Scientific Decade \citep{sivapalan2003}, there has been relatively little progress in transferring these advances to hydrological models \citep{buytaert2008,gupta2012,hrachowitz2013,weiler2015}. \\

%% The Darcy-Richards equation \citep{richards1931}, derived at laboratory scale under conditions that are not generally found in the field \citep{beven2012-b,beven2013}, is still widely used in process based hydrological models and land surface schemes to simulate unsaturated flow in soils \citep{beven2013}. As a result, process-based models must be calibrated to account for spatial heterogeneity, nonlinearity of hydrological processes and interaction between processes at various scales \citep{mcdonnell2007,gupta2012}. The various data streams now available to hydrologists provides the opportunity to explore gaps in knowledge and develop new hypotheses about hydrological processes and systems \cite{beven?}. For example, recent field scale experiments yielding isotopic data from various sites have led to new hypotheses about the partition of water in the critical zone between plant transpiration and groundwater recharge and streamflow \citep{brooks2010,evaristo2015}. Reviewing the main outcomes of the Predictions in Ungauged Basins Scientific Decade, \citet{hrachowitz2013} highlights the need to continue improving dialogue between experimentalists, modellers and theoreticians as a major challenge to the community. \\

%% analysis of epistemic uncertainty, to the extent that it can be isolated, 
%% The main criticism of GLUE is that it is based on a subjective assessment about what consistutes behavioural versus non-behavioural \citep{clark2011,montanari2012}. Meanwhile statistical frameworks ostensibly provide an objective measure of uncertainty but, according to \citep{beven2012}, they wrongly assume that all model uncertainty is aleatory, leading modellers to 'overestimate the information content of the model residuals' \citep{beven2012}. \\

%% According to \citet{dibaldassarre2015}, epistemic uncertainty can further be divided into that which is known to be unknown, unknown to be unknown and wrongly assumed to be known. \\

%% As \citet{beven2015} observes, there is considerable uncertainty about the appropriate type of uncertainty analysis for different applications. 

%% \citep{beven1989}

%% Still to discuss:
%% FRAMES???
%% SUPERFLEX \citet{fenicia2011}
%% FARM \citet{euser2013}

\section{Software design}
The RHydro package implements a set of classes and methods designed to handle different types of data from hydrology and other disciplines and to form the basis of a common interface to hydrological models. The package is based on the S4 system for object-oriented programming \citep{chambers1998,chambers2008}. This system is better suited to complex data structures compared to the alternative and more informal S3 system because objects are validated against a formal class definition when they are created. This minimally ensures that each component, or ``slot'' in S4 terminology, has the correct class but also allows the imposition of additional validity criteria through a validity function included with the class definition. \\

%% Object-oriented programming is based on the concepts of data abstraction, encapsulation, inheritance and polymorphism \citep{}. Encapsulation is the act of concealing the implementation of data in objects so that the user of the data does not need to be concerned with where, and in what form, the data is stored \citep{}. Data abstraction is the notion of reducing an object to its essential characteristics for a given application in order to reduce complexity and improve efficiency \citep{}. Inheritance allows new class definitions to include the properties of existing classes \citep{}. Polymorphism is the idea that a given method has different implementations for objects belonging to different classes. 

%% http://codebetter.com/raymondlewallen/2005/07/19/4-major-principles-of-object-oriented-programming/

%% In object-oriented programming, classes provide an abstract representation of a real-world object \citep{}. 
\subsection{Classes}
According to \citet{chambers1998}, `classes are the fundamental organising principle for data'. Hydrology studies the distribution and quality of water in space and time \citep{}. Thus, hydrological data has spatial and temporal characteristics. The class diagram for RHydro is shown by Figure~\ref{fig:classdiagram}. The RHydro package is built on three classes representing different space-time geometries: HydroSTF, HydroSTS and HydroSTI. These classes inherit from \textbf{spacetime} classes STF, STS and STI, respectively, which all derive from base class ST \citep{pebesma2012}. They include additional slots \texttt{z} and \texttt{endz}, analogous to \texttt{time} and \texttt{endTime} attributes in class ST, to define depth profiles. This is important for hydrological and meteorological variables measured and simulated at specific vertical levels above or below the earth's surface such as soil moisture and wind speed. Classes derived from HydroSTF, HydroSTS and HydroSTI include a \texttt{data} slot to represent data in various formats. Objects belonging to these classes should represent a single hydrological variable. An essential feature of the HydroST classes in the context of service orchestration is the inclusion of a slot \texttt{metadata} to provide a clear, unambiguous description of the data using entries from the CUAHSI controlled vocabulary \citep{horsburgh2013}. \\

%% see caGrid \citep{saltz2006}

\begin{figure}[t]
  \includegraphics[width=12cm]{figs/f02_class_diagram_revised.pdf}
  \caption{Class diagram in the Unified Modeling Language (UML) for \textbf{RHydro}, showing the main classes and methods included in the package.}
  \label{fig:classdiagram}
\end{figure}

\begin{table*}[t]
\caption{Methods included in the \textbf{RHydro} package}
\begin{tabular}{ p{3.5cm} p{8.5cm} }
%% \tophline
\toprule
Table           & Description \\
\midrule
VariableName    & TODO \\
VerticalDatum   & TODO \\
Speciation      & TODO \\
SampleMedium    & TODO \\
ValueType       & TODO \\
DataType        & TODO \\
GeneralCategory & TODO \\
SampleType      & TODO \\
CensorCode      & TODO \\
TopicCategory   & TODO \\
%% \bottomhline
\bottomrule
\end{tabular}
\label{table:cvtables}
%% \belowtable{}
\end{table*}

Class HydroSTF represents the geometry of data with a full space-time grid, which means that for \textit{n} spatial features, which may be points, lines, polygons or grid cells, and \textit{m} time points, $n*m$ data points are available \citep{pebesma2012}. Three derived classes of HydroSTF include data in different formats:

\begin{description}
  \item[HydroSTFDF] objects store data as a \texttt{data.frame} in long format with columns representing depth profiles. This contrasts with STFDF objects from \textbf{spacetime} where columns are assumed to refer to separate variables.
  
  \item[HydroSTF.raster] objects represent spatially gridded data stored as a RasterStack object from package \textbf{raster}. For a geometry with \textit{m} time points and \textit{p} depth profiles the RasterStack has $m*p$ layers with depth cycling fastest. The number of spatial features equals the number of cells in the RasterStack object.
  
  \item[HydroSTF.array] objects, which also represent spatially gridded data, store data an array with four dimensions (time, x, y, z).
\end{description}

Of these derived classes HydroSTFDF is the most flexible because it can represent the most spatial feature types (points, lines, polygons and pixels). A typical use of this class would be to represent precipitation data collected over regular time intervals by a network of rain gauges. Classes HydroSTF.raster and HydroSTF.array should be used to represent spatially gridded data products such as those derived from remotely sensed data or the output of distributed hydrological models. \\

Class HydroSTS represents data on a sparse space-time grid. This is similar to a full space-time grid except only non-missing data is stored. In these objects, an index \textit{[i,j]} is associated with each data value giving the spatial feature \textit{i} and time point \textit{j} to which it belongs. This layout can be more efficient than a full space-time grid under various circumstances described by \citet{pebesma2012}. Data is included as a \texttt{data.frame} in the derived class HydroSTSDF. Data suited to this layout include the activation of flood defence systems or rainfall data in regions with extended dry spells. \\

Where the first two classes represent lattice layouts, in which spatial features have data values for multiple time points, class HydroSTI represents an irregular layout in which there is no defined space-time grid. In this case the number of data points equals \textit{n} spatial features and \textit{m} time points such that a data value \textit{k} is associated with spatial feature \textit{k} and time point \textit{k}. Objects inheriting from HydroSTI therefore include a spatial feature and point for each data value. Hydrological data with an irregular space-time layout include the time and location of burst pipes in a water supply network. It can also be used when the structure of a data set is unknown and then promoted to HydroSTF if it meets the requirements of this class. \\

%% There is a need to provide a common interface to the various data types and formats encountered in hydrology. 
To avoid \textit{ad hoc} solutions to model coupling there should be an intuitive way to group various model inputs so that they can efficiently be transferred between services. A well-understood concept in hydrology is that of the catchment, ... We abstract this concept... The HydroCatchment is a container class for data and information covering a region of interest and forms the basis of a common interface to services within a service-oriented architecture. Slots \texttt{area} and \texttt{network} and \texttt{outlet} represent physical characteristics of a hydrological catchment. Data elements within HydroCatchment objects are objects deriving from HydroSTF, HydroSTS or HydroSTI classes and, therefore, include metadata entries from the CUAHSI controlled vocabulary. This enables service interfaces to receive a single HydroCatchment object, extract data from the object using accessor (getter) functions, send it to the service in the required format, parse the output data from the service, update the HydroCatchment object using mutator (setter) functions and, finally, return the updated object to the workflow. \\

\subsection{Methods} %% TODO: Table showing methods
Methods for the RHydro data classes are shown in Table~\ref{table:methods}. Several methods are written for generic functions defined in other packages or base R for manipulating spatial, temporal or spatiotemporal data. In the following examples we use simple, artificial data objects to illustrate the key methods defined in the package. \\

\begin{table*}[t]
\caption{Methods included in the \textbf{RHydro} package}
\begin{tabular}{ p{3.5cm} p{8.5cm} }
%% \tophline
\toprule
Function name & Description \\
\midrule
crs           & Coordinate reference system \\
diff          & Time difference \\
dim           & Dimensions \\
extent        & Spatial extent \\
gridded       & Test whether an object is spatially gridded \\
metadata      & Get or set object metadata \\
names         & Get or set object name \\
units         & Get variable units \\
%% \bottomhline
\bottomrule
\end{tabular}
\label{table:methods}
%% \belowtable{}
\end{table*}

\subsubsection{Creation}
Constructor functions HydroSTF, HydroSTI and HydroSTS create objects belonging to the respective classes. The class of the data argument, if provided, determines the derived class of the returned object. For example, if data is a RasterStack object, the constructor function will return an object of class HydroSTF.raster. Object metadata is provided as a named list where names correspond to the names of the CUAHSI controlled vocabulary tables shown in Table~\ref{}. It is not necessary to provide object metadata but if metadata entries are supplied they are validated against the CUAHSI controlled vocabulary if the tables are available in the current R session. Otherwise they are not validated and a warning is supplied. The controlled vocabulary tables can be downloaded from the CUAHSI WaterOneFlow Web service using functionality from package RObsDat, as follows:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Loading required package: methods\\\#\# Loading required package: spacetime\\\#\# Loading required package: raster\\\#\# Loading required package: sp}}\end{kframe}
\end{knitrout}

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(RObsDat)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Loading required package: zoo\\\#\# \\\#\# Attaching package: 'zoo'\\\#\# \\\#\# The following objects are masked from 'package:base':\\\#\# \\\#\#\ \ \ \  as.Date, as.Date.numeric}}\begin{alltt}
\hlkwd{library}\hlstd{(RSQLite)}
\end{alltt}


{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Loading required package: DBI}}\begin{alltt}
\hlkwd{library}\hlstd{(SSOAP)}
\hlstd{con} \hlkwb{<-} \hlkwd{dbConnect}\hlstd{(}\hlkwd{dbDriver}\hlstd{(}\hlstr{"SQLite"}\hlstd{),} \hlkwc{dbname} \hlstd{=} \hlstr{"RODM.db"}\hlstd{)}
\hlstd{sqhandler} \hlkwb{<-} \hlkwd{new}\hlstd{(}\hlstr{"odm1_1Ver"}\hlstd{,} \hlkwc{con}\hlstd{=con)}
\hlkwd{options}\hlstd{(}\hlkwc{odm.handler}\hlstd{=sqhandler)}
\hlkwd{updateCV}\hlstd{()}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in SSOAP::processWSDL("{}http://his.cuahsi.org/ODMCV\_1\_1/ODMCV\_1\_1.asmx?WSDL"{}): Ignoring additional <service><port> ... elements}}

{\ttfamily\noindent\itshape\color{messagecolor}{\#\# Note: method with signature 'PrimitiveSOAPType\#list' chosen for function 'resolve',\\\#\#\ \ target signature 'PrimitiveSOAPType\#SchemaCollection'.\\\#\#\ \ "{}SOAPType\#SchemaCollection"{} would also be valid}}\end{kframe}
\end{knitrout}

\noindent Now the most recent version of the CUAHSI controlled vocabulary is available in the current session. Package RObsDat includes various helper functions to navigate the controlled vocabulary tables. For example, the tables can be searched:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{getMetadata}\hlstd{(}\hlstr{"VariableName"}\hlstd{,} \hlkwc{Term}\hlstd{=}\hlstr{"Discharge"}\hlstd{)}
\end{alltt}
\begin{verbatim}
##        Term Definition
## 1 Discharge  Discharge
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent In addition, it allows users to add terms to controlled vocabulary tables:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{addCV}\hlstd{(}\hlstr{"VariableName"}\hlstd{,} \hlkwc{term} \hlstd{=} \hlstr{"test"}\hlstd{,} \hlkwc{definition} \hlstd{=} \hlstr{"test entry"}\hlstd{)}
\end{alltt}


{\ttfamily\noindent\color{warningcolor}{\#\# Warning in addCV("{}VariableName"{}, term = "{}test"{}, definition = "{}test entry"{}): Skipping existing entry: test}}\begin{verbatim}
## NULL
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent However, as the resulting warning message implies, this facility should be treated with caution because the term is only added to the local copy of the controlled vocabulary. Thus, when the table is updated from the WaterOneFlow Web service any locally added terms will be overwritten. \\ 

In the following toy example we create objects objects \texttt{x} and \texttt{y} with classes \texttt{HydroSTFDF} and \texttt{HydroSTF.raster}, respectively. First, we create the space and time geometries and generate some arbitrary data drawn from a random uniform distribution:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{sp} \hlkwb{<-} \hlkwd{SpatialPoints}\hlstd{(}\hlkwd{data.frame}\hlstd{(}\hlkwc{x}\hlstd{=}\hlnum{1}\hlopt{:}\hlnum{5}\hlstd{,} \hlkwc{y}\hlstd{=}\hlnum{1}\hlopt{:}\hlnum{5}\hlstd{))}
\hlstd{t} \hlkwb{<-} \hlkwd{seq}\hlstd{(}\hlkwd{as.POSIXct}\hlstd{(}\hlstr{"2000-01-01"}\hlstd{,} \hlkwc{tz}\hlstd{=}\hlstr{"GMT"}\hlstd{),} \hlkwc{by}\hlstd{=}\hlstr{"1 hour"}\hlstd{,} \hlkwc{length.out}\hlstd{=}\hlnum{24}\hlstd{)}
\hlstd{dat} \hlkwb{<-} \hlkwd{data.frame}\hlstd{(}\hlkwd{runif}\hlstd{(}\hlkwc{n}\hlstd{=}\hlnum{120}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent Now, we create an object of class HydroSTFDF:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{x} \hlkwb{<-} \hlkwd{HydroSTF}\hlstd{(}\hlkwd{STFDF}\hlstd{(}\hlkwc{sp}\hlstd{=sp,} \hlkwc{time}\hlstd{=t,} \hlkwc{data}\hlstd{=dat),}
              \hlkwc{metadata}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{VariableName}\hlstd{=}\hlstr{"Discharge"}\hlstd{,}
                            \hlkwc{VariableUnitsID}\hlstd{=}\hlnum{52}\hlstd{,}
                            \hlkwc{ValueType}\hlstd{=}\hlstr{"Field Observation"}\hlstd{,}
                            \hlkwc{DataType}\hlstd{=}\hlstr{"Cumulative"}\hlstd{))}
\hlstd{x}
\end{alltt}
\begin{verbatim}
## class           : HydroSTFDF
## dimensions      : 5, 24, 1, 0 (space, time, depth, variables)
## spatial res.    : NA (points)
## temporal res.   : 1 hour
## spatial extent  : 1, 5, 1, 5 (xmin, xmax, ymin, ymax)
## temporal extent : 2000-01-01 GMT, 2000-01-01 23:00:00 GMT (start, end)
## coord. ref.     : NA
## data source     : in memory
## 
## 
## VariableName    :         Discharge
## VariableUnitsID :                52
## ValueType       : Field Observation
## DataType        :        Cumulative
## 
##                            z1
## min values      : 0.003558784
## max values      :   0.9995103
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent To create an object of class HydroSTF.raster we generate a RasterStack object and pass this to the constructor function, using the same time series as before:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{dat} \hlkwb{<-} \hlkwd{brick}\hlstd{(}\hlkwc{x}\hlstd{=}\hlkwd{array}\hlstd{(}\hlkwc{data}\hlstd{=}\hlkwd{runif}\hlstd{(}\hlnum{2400}\hlstd{),} \hlkwc{dim}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{10}\hlstd{,}\hlnum{10}\hlstd{,}\hlnum{24}\hlstd{)))}
\hlstd{y} \hlkwb{<-} \hlkwd{HydroSTF}\hlstd{(}\hlkwc{time}\hlstd{=t,} \hlkwc{data}\hlstd{=dat,}
              \hlkwc{metadata}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{VariableName}\hlstd{=}\hlstr{"Precipitation"}\hlstd{,}
                            \hlkwc{VariableUnitsID}\hlstd{=}\hlnum{52}\hlstd{,}
                            \hlkwc{ValueType}\hlstd{=}\hlstr{"Field Observation"}\hlstd{,}
                            \hlkwc{DataType}\hlstd{=}\hlstr{"Cumulative"}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

\noindent Note that in this case we do not need to supply a Spatial object to the constructor function because this information is derived internally from the RasterStack object. \\

The HydroCatchment class is designed to contain several data objects for a given place. To allow for the fact that providing information for area, network and outlet slots is not always necessary, a simple dummy object is included with the package. In the following example we load this object and update it with the HydroSTFDF and HydroSTF.raster objects created previously:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{data}\hlstd{(hc)}
\hlstd{hc} \hlkwb{<-} \hlkwd{update}\hlstd{(hc,} \hlkwc{data}\hlstd{=}\hlkwd{list}\hlstd{(x, y))}
\hlkwd{names}\hlstd{(hc)}
\end{alltt}
\begin{verbatim}
## [1] "Discharge"     "Precipitation"
\end{verbatim}
\end{kframe}
\end{knitrout}

%% \subsection{Querying}
%% Various methods allow the user to query the spatial and temporal characteristics of Hydro objects. Some of these are shown below:

\subsubsection{Coercion}
Coercion methods for objects belonging to HydroSTF, HydroSTS and HydroSTI classes make it easier to take advantage of methods defined for objects of different classes. Objects of class HydroSTF.raster and HydroSTF.array can always be coerced to HydroSTFDF objects, however, the reverse operation is only possible if the HydroSTFDF object is gridded. In the following example we coerce the HydroSTF.raster object created previously to an object of class HydroSTF.array:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y1} \hlkwb{<-} \hlkwd{as}\hlstd{(y,} \hlstr{"HydroSTF.array"}\hlstd{)}
\hlkwd{class}\hlstd{(y1)}
\end{alltt}
\begin{verbatim}
## [1] "HydroSTF.array"
## attr(,"package")
## [1] "Hydro2"
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent Next, we coerce the HydroSTF.array object back to HydroSTF.raster and compare the result with the original HydroSTF.raster object:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y2} \hlkwb{<-} \hlkwd{as}\hlstd{(y1,} \hlstr{"HydroSTF.raster"}\hlstd{)}
\hlkwd{compare}\hlstd{(y1, y2)}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in compare\_ST(x, ..., extent = extent, coords = coords, crs = crs, : different ST classes}}\end{kframe}
\end{knitrout}

\noindent The function \texttt{as.spacetime} converts objects inheriting from HydroSTF, HydroSTS, HydroSTI to their nearest equivalent \textbf{spacetime} classes. Then, the coercion methods of package \textbf{spacetime}, described in \citet{pebesma2012}, can be applied. For example:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y1} \hlkwb{<-} \hlkwd{as.spacetime}\hlstd{(y)}
\hlkwd{class}\hlstd{(y1)}
\end{alltt}
\begin{verbatim}
## [1] "STFDF"
## attr(,"package")
## [1] "spacetime"
\end{verbatim}
\begin{alltt}
\hlstd{y2} \hlkwb{<-} \hlkwd{as}\hlstd{(y1,} \hlstr{"xts"}\hlstd{)}
\hlkwd{class}\hlstd{(y2)}
\end{alltt}
\begin{verbatim}
## [1] "xts" "zoo"
\end{verbatim}
\end{kframe}
\end{knitrout}

\subsubsection{Indexing}
Indexing allows users to extract or replace subsets of HydroST objects. Methods for HydroSTFDF, HydroSTSDF and HydroSTIDF objects closely follow those for the corresponding \textbf{spacetime} classes described by \citet{pebesma2012}. Individual raster objects can be extracted from HydroSTF.raster objects using double brackets, as follows:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y[[}\hlnum{1}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## class       : RasterLayer 
## dimensions  : 10, 10, 100  (nrow, ncol, ncell)
## resolution  : 0.1, 0.1  (x, y)
## extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
## coord. ref. : NA 
## data source : in memory
## names       : z1.1 
## values      : 0.01012756, 0.9761467  (min, max)
\end{verbatim}
\begin{alltt}
\hlstd{y[[}\hlnum{1}\hlopt{:}\hlnum{5}\hlstd{]]}
\end{alltt}
\begin{verbatim}
## class       : RasterBrick 
## dimensions  : 10, 10, 100, 5  (nrow, ncol, ncell, nlayers)
## resolution  : 0.1, 0.1  (x, y)
## extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
## coord. ref. : NA 
## data source : in memory
## names       :        z1.1,        z1.2,        z1.3,        z1.4,        z1.5 
## min values  : 0.010127562, 0.028995826, 0.022980701, 0.018955839, 0.001029185 
## max values  :   0.9761467,   0.9996975,   0.9995082,   0.9959238,   0.9957950
\end{verbatim}
\end{kframe}
\end{knitrout}

Index methods for HydroCatchment objects are designed to extract or replace objects held in the data slot. The index can be either be numeric or, if the objects have metadata entries, a character vector of variable names to be selected. Double brackets are used to select a single data object whereas single brackets can select one or more objects, returning a HydroCatchment object containing only the selected data:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{x1} \hlkwb{<-} \hlstd{hc[[}\hlnum{1}\hlstd{]]}
\hlkwd{class}\hlstd{(x1)}
\end{alltt}
\begin{verbatim}
## [1] "HydroSTFDF"
## attr(,"package")
## [1] "Hydro2"
\end{verbatim}
\begin{alltt}
\hlstd{y1} \hlkwb{<-} \hlstd{hc[[}\hlstr{"Discharge"}\hlstd{]]}
\hlkwd{compare}\hlstd{(x1, y1)}
\end{alltt}
\begin{verbatim}
## [1] TRUE
\end{verbatim}
\begin{alltt}
\hlkwd{class}\hlstd{(hc[}\hlnum{1}\hlstd{])}
\end{alltt}


{\ttfamily\noindent\bfseries\color{errorcolor}{\#\# Error in (function (classes, fdef, mtable) : unable to find an inherited method for function 'geometry' for signature '"{}HydroCatchment"{}'}}\begin{alltt}
\hlkwd{class}\hlstd{(hc[}\hlnum{1}\hlstd{,} \hlkwc{drop}\hlstd{=}\hlnum{TRUE}\hlstd{])}
\end{alltt}
\begin{verbatim}
## [1] "HydroSTFDF"
## attr(,"package")
## [1] "Hydro2"
\end{verbatim}
\end{kframe}
\end{knitrout}

%% \subsubsection{Arithmetic and mathematical functions}
%% Arithmetic and mathematical methods for HydroST objects allow them to be used in calculations. A full list of supported operations is provided in the package documentation. Objects of the same derived class can be supplied to arithmetic operators if they have the same spatial and temporal characteristics. For example:

%% %% TODO

%% \noindent Numeric, Spatial and time-based objects can also be supplied. \\

\subsubsection{Aggregation and resampling}
For objects of classes HydroSTFDF, HydroSTIDF and HydroSTSDF spatial and temporal aggregation and overlay methods are thin wrappers to the methods for objects of corresponding \textbf{spacetime} classes described in \citet{pebesma2012}. Gridded HydroSTF objects can additionally be spatially aggregated to a lower resolution or resampled... by taking advantage of the \texttt{aggregate} and \texttt{resample} methods of package \textbf{raster}. To achieve this, gridded HydroSTFDF and HydroSTF.array objects are coerced to HydroSTF.raster objects, aggregated, and coerced back again. Some examples of aggregation are shown here: \\

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{y1} \hlkwb{<-} \hlkwd{aggregate}\hlstd{(y,} \hlkwc{fact}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{FUN}\hlstd{=mean)}
\hlkwd{dim}\hlstd{(y1)}
\end{alltt}
\begin{verbatim}
##     space      time     depth variables 
##        25        24         1         0
\end{verbatim}
\begin{alltt}
\hlstd{y2} \hlkwb{<-} \hlkwd{aggregate}\hlstd{(y,} \hlkwc{fact}\hlstd{=}\hlnum{5}\hlstd{,} \hlkwc{FUN}\hlstd{=mean)}
\hlkwd{dim}\hlstd{(y2)}
\end{alltt}
\begin{verbatim}
##     space      time     depth variables 
##         4        24         1         0
\end{verbatim}
\end{kframe}
\end{knitrout}

\noindent In the next example we create a new raster object with the same spatial extent as the HydroSTF.raster object created earlier but a different spatial resolution, and use this as the basis for resampling the HydroSTF.raster object:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{r} \hlkwb{<-} \hlkwd{raster}\hlstd{(}\hlkwd{matrix}\hlstd{(}\hlkwc{data}\hlstd{=}\hlnum{NA}\hlstd{,} \hlkwc{nrow}\hlstd{=}\hlnum{6}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{6}\hlstd{))}
\hlstd{y1} \hlkwb{<-} \hlkwd{resample}\hlstd{(y, r,} \hlkwc{method}\hlstd{=}\hlstr{"bilinear"}\hlstd{)}
\hlkwd{geometry}\hlstd{(y1)}
\end{alltt}
\begin{verbatim}
## class           : HydroSTF
## dimensions      : 36, 24, 1, 0 (space, time, depth, variables)
## spatial res.    : 0.166666666666667, 0.166666666666667
## temporal res.   : 1 hour
## spatial extent  : 0.08333333, 0.9166667, 0.08333333, 0.9166667 (xmin, xmax, ymin, ymax)
## temporal extent : 2000-01-01 GMT, 2000-01-01 23:00:00 GMT (start, end)
## coord. ref.     : NA
\end{verbatim}
\end{kframe}
\end{knitrout}

%% \subsection{Visualisation}
%% Visualisation is an important tool in hydrological data analysis, ... \\

\section{Example applications}

In this section we present two example applications of the RHydro framework. In the first case we show how RHydro facilitates the use of Topmodel \citep{beven1979}, a well known hydrological model, to simulate discharge in the Wye catchment in mid-Wales. The example serves to demonstrate the use of RHydro in hydrological modelling workflows. In the second example we use the socio-hydrological model developed by \citep{garcia2016} to show the value of RHydro to socio-hydrological modelling.

\subsection{Plynlimon}
The Plynlimon research catchments... The original data set was obtained from the Centre for Ecology and Hydrology. A package vignette shows how to download the raw data files from \url{https://github.com} and create a single STFDF object containing observed meteorological data from a network of automatic weather stations. Having created such an object, a version of which is included with the package, it is straightforward to create HydroST objects representing individual variables, as shown in Figure Y. If the CUAHSI controlled vocabulary is made available by implementing the code in Figure X the validity of the metadata entries for the HydroST objects is checked automatically: invalid entries result in an error. \\

\subsubsection{Evapotranspiration}
Topmodel requires reference evapotranspiration for each time point in the simulation \citep{}. Associating each data object with metadata entries from a controlled vocabulary allows users to write functions that checks the data object contains the correct variable. %% In addition, it means that a single function can automatically follow different methods to achieve the same outcome depending on the variables contained in an object of class HydroCatchment.
To illustrate how this can be done in practice we have developed an experimental package \textbf{FAO56} which implements several equations from the Food and Agricultural Organisation (FAO) Irrigation and drainage paper 56 \citep{allen1998}. This document provides guidelines for computing crop water requirements using the Penman Monteith combination equation. Reference evapotranspiration... Equation 6 can be written:

\begin{equation}
%% TODO: equation
\end{equation}

\noindent where... In many situations... For this reason the FAO56 contains a number of methods to compute missing variables from... The method for HydroCatchment objects makes an assessment of the variables available and, for each input variable, whether it is available or if it needs to be calculated. If the latter, a method is chosen following the preferences described in paper 56. 

%% \subsection{Topmodel}
%% Topmodel is a semi-distributed hydrological model, originally developed by \citet{beven1979} and described extensively elsewhere \citep[e.g.][]{}, that partitions rainfall into overland flow, unsaturated zone recharge and saturated zone flow \citep{lane2004}. The R package \textbf{topmodel} \citep{} provides a convenient wrapper for the original Fortran code. ...To illustrate the procedure of creating... procedure we have defined a subclass HM.topmodel to represent Topmodel, as shown in Figure X. \\

%% TODO: draw UML diagram illustrating class HM.topmodel

\subsection{Reservoir operation}
Reservoir operation is a classic problem... Here, we adapt the example of \citep{garcia2016} to the RHydro framework. \\

\section{Discussion}

%% The following paragraph from /home/simon/r_hydro_info/blueprint.pdf (TODO: references)
Hydrological modelling and data analysis must increasingly handle large, complex data sets. To facilitate workflows... we have designed and implemented a set of classes and methods... The examples show some potential applications of the package. Hydrological science faces a number of key challenges around code availability, reproducibility of scientific results... Addressing the challenges in scientific hydrology requires integration of information from diverse sources, ``is data and computationally intensive" and collaboration between researchers across disciplines \url{https://irods.org/wp-content/uploads/2015/06/Tarboton-HydroShare.pdf}. [...] We argue that \textbf{RHydro} should be viewed as a first step towards tackling these issues. \\

Various solutions have been proposed, including the development of a community hydrological model \citep{weiler2015}. \\
WaterML is an XML dialect for representing hydrological time series data \citep{}. The current version, WaterML 2.0, is an open standard of the Open Geospatial Consortium (OGC) \citep{}. An R package, \textbf{WaterML}, allows R users to interact with the CUAHSI... \\

Over time, alternative approaches will be developed and the community will converge on the most efficient solution. In all likelihood it will not resemble RHydro but this does not detract from its potential  

Realising the Model Web is highly ambitious and will rely on bottom-up, community driven progress \citep{}. According to \citet{nativi2013} the Model Web is based on four main principles: `open access, minimal barriers to entry, service driven and scalability'. Any solution meeting these... is a step towards... \citet{nativi2013} \\

Currently RHydro implements the CUAHSI ontology. The example of the reservoir operations model demonstrates the limitations of this approach because, as a system originating from the hydrological sciences, it does not support many terms that might be encountered in other disciplines. It is possible to suggest new entries to the ontology but it is unclear whether there is support for extending the scope of the ontology. Furthermore, given the range of problems encountered, particularly in socio-hydrology, it is unlikely that a single ontology will contain all the relevant terms all of the time. \\

The Model Web would make it easier to discover, access and use models and data \citep{schade2012}, improving the reproducibility of scientific results and making models and data, including uncertainty estimation, available to decision-makers \citep{nativi2013}.

The example application of RHydro to the reservoir operations model can be seen as an implementation of the Model Web without web services. The next stage of development of RHydro is to develop models as web services... There remain considerable difficulties with developing model encapsulations for web services, as discussed by \citet{yue2015}. \\

One of the main goals in science is the exchange of ideas. Mathematical equations are used to communicate the structure of theories, computer code needs to be communicated to show how these theories were applied \citep{buytaert2008}. At best, this is done at a relatively high level language that is compact and widely used. An open, free software environment such as R provides the means to communicate the latter, efficiently. Teaching how we develop, implement, combine, run and verify models is equally served by a free environment that offers much functionality and high-level language constructs. \\
%% end

Adopting a new, flexible approach to model coupling allows the interoperability of models across disciplines to be prioritised from the beginning \citep{goodall2011}. 

it is impossible to guarantee the reproducibility of model results unless the implementation details, including the model source code, is freely available \citep{ince2012}. Moreover, it forces the duplication of work \citep{}. C
Efficient model development strongly depends on the availability of models as free and open source software

The example use cases for Plynlimon and ... demonstrate the potential of RHydro. However, there remains much work to be done in order to realize the Model Web for hydrology. First, there needs to be... Cloud computing is the use of computer hardware and software delivered as a service over the Internet to store, manage and process data \citep{}. This enables the efficient utilisation of computer infrastructure by multiple users and removes the need to install and maintain various software components locally \citep{burger2012}. ``the complexity of most environmental models typically confines them to scientific laboratories and academic computer clusters..." \citep{buytaert2012}. %% Well known cloud-based services include the suite of Google products... Google's Earth Engine, which ..., has been used to... 
Providing models as web services with accessible user interfaces reduces the gap between science and policy makers. Cloud computing will be important to ensure community engagement and participation with the development of so called ``hyper-resolution" models because the computing power required for such models will exceed that provided by desktop computers. \\

As the principles of socio-hydrology are directed towards global and regional problems, as envisaged by \citep{lall2014}, model complexity will increase.

The Model Web, as proposed by \citet{geller2007}, is a vision for a system of interoperable models and data available through the Internet as web services. In this vision model inputs could be outputs from other models or they may be observed or measured values received in real time from sensors (which may also be considered a model output \citep{geller2007,pebesma2010,beven2012}) or from databases. Loosely coupled models interacting through web services has several advantages over tightly coupled models that lack flexibility and often require substantial modification of model source code  \citep{bulatewicz2012,lu2012} (model removed from development cycle) The implementation of the Model Web for hydrology would facilitate a system ``in which modelling methods, databases, observations and uncertainty estimation are integrated seamlessly...", such as that envisaged by \citet{beven2007}. Furthermore, scientific research carried out using the Model Web would be accessible and fully reproducible \citep{bastin2013}. The UncertWeb project \url{http://www.uncertweb.org/} explored how to manage uncertainty in instances of the Model Web \citep{bastin2013}. HydroShare is a collaborative environment for data sharing, analysis and modelling currently under development by CUAHSI... It will be exposed as a web-service. In many ways the R system may be thought of as an implementation of the Model Web without the use of web services, because... % From /home/simon/r_hydro_info/RHydro_new.pdf\\

The aim of the current IAHS Scientific Decade \citep[Panta Rhei-Everything Flows][]{montanari2013} is to improve the predictive capacity of hydrological models for sustainable water resources management in the context of rapid environmental and social change. This requires scientific workflows that include human-environment interactions \citep{laniak2013,nazemi2015,wheater2015}. Representing complex systems in a single model structure is both challenging and undesirable \citep{}. Integrated environmental modelling is an approach where several models representing... are linked in order to provide a coherent representation of a system. %% Earth system models consist of tightly coupled model components representing atmosphere, oceans, land and sea ice \citep{valcke2012}. However, 
In water resources management there is a need for a flexible approach to model coupling because of the diverse range of problems encountered \citep{}. The lack of a common interface amongst hydrological models... \\

\citet{pebesma2012} highlights a number of areas where the \textbf{spacetime} package could be improved. The \textbf{RHydro} package has provided solutions to some o these limitations. For example, it shows how \textbf{raster} classes can be represented... It support of the CUAHSI controlled vocabulary... albeit in the hydrological sciences only. There remain a number of areas... \\

A lack of data means that models are untested across a broad range of catchments and... One solution to the lack of data is leveraging the 'Internet of things' to improve monitoring networks \citep{buytaert2014}.

Future work on RHydro will focus on identifying use cases and applications to further refine its functionality. Particular focus will be given to modelling human-environment interactions through model coupling. \\

 %% This makes it harder to compare different models, particularly in the context of models as working hypotheses \citep{clark2011}. \\

%% Points for discussion:

%% \begin{itemize}
%% \item The RHydro package could be used as the basis for a new community hydrological model of the type called for by \citep{weiler2015}
%% \item How can users contribute to RHydro development? Mention need for models and data as web services
%% \item Data heterogeneity: heterogeneity of meaning and heterogeneity of format
%% \end{itemize}

\section{Conclusion}

The main contribution of RHydro [...] \\

% not used:

%% \subsubsection{Controlled vocabulary}
%% A controlled vocabulary is a collection of words and phrases that is used to describe information and data in a consistent way \citep{horsburgh2008}. Each term in a controlled vocabulary has a single, unambiguous meaning \citep{horsburgh2008}. In hydrology, the controlled vocabulary of the Consortium of Universities for the Advancement of Hydrologic Science (CUAHSI) is part of its Hydrologic Information System (HIS) ... WaterML... 
%% Package \textbf{RObsDat} \citep{} provides a convenient interface to the CUAHSI Web services. It was designed to The following code snippet shows how to make the CUAHSI controlled vocabulary available within the current R session and update the various tables from the CUAHSI Web service. The \texttt{getMetadata()} function in \textbf{RObsDat} allows users to search for particular terms in the controlled vocabulary tables.  \\

%% Semantic heterogeneity impedes the discovery, retrieval, integration and exchange of data and information \citep{}.

%% According to \citet{nativi2013}, `a clear information model is essential for accommodating the different resources published in the Model Web'.

%% However, while R includes many of the tools for handling hydrological data, there is a need to explore ways of including semantic information... \citep{geller2014}. 

%% Ontologies are an essential aspect of the Model Web because resources in the network must be able to act upon data objects without human interference. \\

%% ... an ontology is `a representation of the knowledge within a domain of interest' \citep{madin2007}, to describe and synthesize data elements from diverse sources \citep{shadbolt2006}. 

%% These classes and methods will enable... R to be used as the orchestration engine within a service-oriented architecture. Initially, services will be functional wrappers to hydrological models. In the future, these services will be Web services coupled over a distributed network. \\
%% In the long-term, we envisage that data may be stored over a distributed system... Methods should provide... As well as representing individual data objects, representing specific hydrological variables, we intend to provide a class for catchments which allows data, parameters... 
%% The first design goal of RHydro is to provide classes and methods to facilitate hydrological modelling and data analysis.
%% \textit{abstraction} and \textit{encapsulation}. We want to represent the microarray concept in a way that makes sense to the users without distracting them with unnecessary technicalities... We want the users to comprehend microarrays in R like they know them in real life i.e. manipulate the abstract concept microarray while keeping all the underlying technical details, the implementation, hidden, or encapsulated''
%% The RHydro package follows an object-oriented design using the S4 system \citep{chambers2008}. This system provides... It is strongly inspired by the \textbf{spacetime} package \citep{pebesma2012}. \\
%% Our aim is to encapsulate spatial, temporal and spatio-temporal hydrological data in a way that means users of RHydro are not unnecessarily concerned with technical details about how or where data is stored. We buil

%% Table X lists some high-level packages for retrieving meteorological and hydrological data from the web. \\ %% include WaterML

%% \begin{sidewaystable}[ph!]
%% \caption{R packages for hydrological modelling and data analysis.}
%% \centering
%% \begin{tabular}{ l l l }
%% %% \tophline
%% \hline
%% Package & URL & Description \\
%% %% \middlehline
%% \hline
%% HydroGOF           & Goodness-of-fit measures for calibration and validation of hydrological models & \\
%% HydroTSM           & Tools for hydrological time series analysis & \\
%% Hydrosanity        & & \\
%% RMWAGEN            & & \\
%% Evapotranspiration & & \\
%% topmodel           & & \\
%% dynatopmodel       & & \\
%% Wasim              & & \\
%% TUWmodel           & & \\
%% SWATmodel          & & \\
%% %% \bottomhline
%% \hline
%% \end{tabular}
%% \label{table:packages}
%% %% \belowtable{}
%% \end{sidewaystable}

%% Several hydrological models have been implemented as R packages, including Topmodel, Dynamic Topmodel \citep{metcalfe2015}, the HBV model and the Soil and Water Assessment Tool (SWAT).
%% Low-level packages for spatial, temporal and spatio-temporal data analysis and manipulation form the basis of high-level packages for hydrological modelling and data management. 
%% It offers a wide range of low-level to high-level plotting facilities that can be sent to various graphics devices or dynamic Web interfaces \citep{gesmann2011}. \\

%% \subsection{Summary and design goals}

%% Hydrological models are represented by the HM class. The HM class provides an entry point for users and developers to define methods for hydrological models. The procedure is to define a subclass of HM that is specific to the model or process in question. This should include a validity function to ensure the object contains the correct data content and format. Individual models should be represented by derived classes inheriting from class HM. It is included solely for the purpose of providing users and developers with a class to extend to represent individual models. \\

%% %% summary of literature review
%% There is a strong need to improve the representation of physical processes in hydrological models \citep{beven2012}. Individual models should be viewed as a set of coupled hypotheses about the functioning of the hydrological system \citep{clark2011}. Isolating coupled hypotheses should make it easier to identify sources of epistemic uncertainty \citep{}; however, it is difficult to compare hypotheses in different model structures because the implementation of the current generation of hydrological models varies so widely \citep{}. Furthermore, it is still the case that representations of many physical processes in models are contradicted by field experiments \citep[e.g.][]{mcdonnell2007}. Meanwhile the emerging discipline of socio-hydrology addresses complex problems involving coupled systems \citep{sivapalan2013}. According to \citet{salas2012}, a framework for model coupling 'should support modularity, flexibility and interoperability'. Individual model components should be independent in terms of development and implementation and they should be able to function autonomously as well as within the coupling framework. Component-based modelling facilitates model development by clearly separating coupled hypotheses and allowing improvements to made to one part of the model without needing to change other parts \citep{kelly2013,clark2015-b,blair2016}. However, there are substantial drawbacks to existing frameworks for model coupling, including the fact that they require the source code to be modified as well as platform dependency. \\

%% %% Model Web
%% The vision of the Model Web builds on the concept of component-based modelling by allowing individual components to be connected over a network following a service-oriented architecture \citep{geller2007}. Model components are exposed as Web services and may have no awareness of other services in the network. Service orchestration is a key aspect of service-oriented architectures... 

%% In this context we propose RHydro as an orchestration engine for service-oriented... The R system is an attractive platform to develop such an implementation for various reasons. Since it already supports a wide range of data types we do not need to spend time developing solutions for the wide range of data types and formats encountered in hydrology. There is an active community of hydrologists and socio-hydrologists using R \citep{}, ensuring a large potential user base and lowering the barriers to entry. The fact that several hydrological models are already available as contributed packages (e.g. Topmodel, HBV) or scripts (e.g. \citet{garcia2016} means it is an ideal environment in which to test ideas and functionality. \\

%% Thus, as \citet{nativi2013} argues, any approach following these general concepts helps to move the modelling community towards the long-term vision. 
%% Models encapsulate knowledge and modelling itself is a learning process \citep{box1976}. 
%% In this context, we propose RHydro as a model of the Model Web that provides a means to explore potential issues and challenges that may be encountered as the long-term vision is realised. In doing so, we aim to provide a tool that is useful for hydrological modelling and data analysis, particularly model coupling. \\

%% Rather, we aim to provide classes and methods that can be used as the basis of a common interface for new and existing models and provide a means to improve the interoperability of existing packages for hydrological data analysis.

%% Finally, R provides functionality for high-performance and parallel computing with convenient interfaces to run R process on Hadoop clusters and Amazon Web Services, for example. 
%% (screen, file formats)
%% In addition, R offers topological manipulation of geometries \citep{rundel2012}, as well as analysis of network data \citep{csardi2006}. 
%% It also contains packages for parsing data from the web such as \textbf{RCurl} and \textbf{SSOAP}. \\
%% which compiles and runs on a wide variety of Unix platforms, Windows and MacOS \citep{pebesma2012}.

%% Several packages for retrieving and processing hydrological data from Web services have emerged: \textbf{hddtools} allows users to download and process data from sources such as the Global Runoff Data Centre, Met Office Hadley Centre Observation Data and NASA's Tropical Rainfall Measuring Mission, 

%% One interesting package is \textbf{hydromad} \citep{andrews2013}, which provides a set of functions to construct and compare conceptual, lumped hydrological models including various interchangeable routines for soil moisture accounting and flow routing. This can be seen as a way of exploring model structural uncertainty, albeit using simple conceptual models rather than process-based models. 

%% Through these packages, R includes several classes for representing time and sophisticated methods for time series analysis through contributed packages such as \textbf{zoo} and \textbf{xts}. The \textbf{sp} package provides dedicated classes and methods for representing different types of spatial data including points, lines, polygons and pixels. Packages exist for analyzing spatial data \citep{bivand2013} and spatio-temporal data \citep{pebesma2012}. The ability to handle spatial and spatio-temporal data includes going from one representation to another (regridding, aggregation, disaggregation), but also geostatistical interpolation and stochastic simulation \citep{pebesma2004}. Package \textbf{rgdal} \citep{bivand2014}, which provides an interface to the GDAL and OGR libraries, ensures interoperability with most spatial raster and vector file formats and provides transformation between spatial reference systems through the PROJ.4 cartographic projections library \citep{}. Package \textbf{raster} \citep{hijmans2014} provides classes and methods for analysing raster data. In addition, R offers topological manipulation of geometries \citep{rundel2012}, as well as analysis of network data \citep{csardi2006}. R provides functionality for high-performance and parallel computing with, for instance, convenient interfaces to run R process on Hadoop clusters. Running R on Amazon Web Services is also straightforward \citep{}. It offers a wide range of low-level to high-level plotting facilities that can be sent to various graphics devices (screen, file formats) or dynamic web interfaces \citep{gesmann2011}. It also contains packages for parsing data from the web such as \textbf{RCurl} and \textbf{SSOAP}. \\
%% which compiles and runs on a wide variety of Unix platforms, Windows and MacOS \citep{pebesma2012}.
%% The development of R is strongly established in the areas of statistical software and data analysis \citep{chambers2008}. 
%% Moreover, a lack of convergence on a community hydrological model has resulted in numerous hydrological models that are written in different programming languages, built for different operating systems and accessed through different types of user interface \citep{buytaert2008,weiler2015,yue2015}. \\

%% More recently, \citet{goodall2014} used an \textit{ad hoc} orchestration engine to simulate integrated urban infrastructure systems by coupling models of water, transportation and structures exposed as Web services. 

%% The object-oriented nature of data-processing languages makes them an efficient means to couple models and data \citep{ousterhout1998}. \\

%% Service-oriented computing is an essential concept of distributed computing `where the Internet is used not only for delivering information from machines to humans, but also between machines themselves' \citep{huhns2005}. \\
%% The component implementing the Muskingham Routing method was a Web service while the other two components were local services \citep{goodall2011}. 
%%  
%% For example, \citet{goodall2013} coupled a regional climate model with the Soil Water Assessment Tool using Web services, demonstrating the potential for service-oriented architectures to integrate water resources management activities with earth system models, called for by \citep{nazemi2015}. 

%% It enables a form of component-based modelling where communication between system components is done over a network rather than locally \citep{huhns2005,goodall2011}.   
%% Models and databases are encapsulated, or wrapped, using a common interface, avoiding the need to modify the source code of the original components \citep{}.

%% Service-oriented architectures hold great promise for water resources management because of the diverse range of problems encountered as well as the epistemic uncertainty about the appropriate model structure to represent a system.

%% (\url{https://cran.r-project.org/web/views/WebTechnologies.html}).
%% In some cases the original model code has been wrapped in a relatively high-level language such as R and Python. 
%% A package for the transfer of  available as an R package allowing hydrological data discovery and sharing from the R console. These packages typically perform a certain part of hydrological workflows. 
%% For example, both Topmodel and Dynamic Topmodel are available as R packages. This provides a more user-friendly model interface and makes it easier to handle input/output and visualise model results. \\

%% \subsection{Summary}
%% TODO

%% Shiny apps are valuable to improve accessibility to scientific results and... [\citep{garcia2016}]

%% The problem is compounded by the fact that the source code of many hydrological models is not available, making it difficult to understand decisions made by different modelers... \\

%% This has partly arisen because hydrological models are developed in isolation and lack a common interface [...] efforts such as the Framework for Understanding Structural Errors (FUSE) \citep{clark2008}.

%% Despite considerable advances in fields such as weather forecasting and ocean modelling there has been little progress in distributed, physics-based hydrological models \citep{beven2001,buytaert2008}. 
%% Models such as... 

%% %% model development as a consequence of uncertainty analysis
%%  Current models are usually written in programming languages such as C and Fortran. The fact that some of the most widely used models, especially amongst the research community, are those with open-source implementations suggests that ease of use and accessibility is a major consideration for hydrologists. 

%% Meanwhile land surface schemes, originally developed to provide the lower boundary condition for climate models, are increasingly used for hydrological modelling at regional, continental and global scales \citep[e.g.][]{nazemi2015}. With increasing computing power there is a drive for so called hyperresolution models (spatial resolution of the order of 1km or less) that resolve fluxes at finer spatial scales \citep[e.g.][]{wood2011}. Earth system models are used for water resources management... However, as \citet{beven2015} argues, even at spatial resolutions higher than those proposed by \citet{wood2011} there will be considerable subgrid heteregeneities that are not properly resolved. Furthermore, there are many aspects of the hydrological cycle that are not captured by earth system models, particularly concerning human intervention to the hydrological cycle. Irrigation... \citep{nazemi2014}. In many places the arbitrary distinction between groundwater and surfacewater... \citep{}. 

%% We suggest that the increasing popularity of earth system models for hydrological modelling is due in large part to the fact that these models are usually open-source and freely available with community support. While \citet{beven?} is highly critical of the use of these models for hydrological modelling, in many cases their use is borne out of the fact that many specialised distributed hydrological models are not fit for purpose. Selecting an appropriate model for a specific task usually requires some iteration: if models are not freely available they are usually excluded. In a more recent paper, \citet{beven2015?} argue for the adoption of a community hydrological model... This is the status of many land surface schemes... 

%% Models frequently rely on equations that have parameters that cannot be measured directly, either because they do not represent physical quantities or because the physical quantity they represent is difficult to observe \citep{}. Empirical and conceptual models are calibrated by manually or automatically selecting values such that the model output matches a measured variable to the extent required for the specific application. 

%% [see review of previous attempts in \citep{mendoza2014}] \\

%% To overcome this limitation, it must be more straightforward to isolate individual process representations in different models so that hypotheses can be properly tested \citep{clark2011}. 

%% Although there is some debate about the most appropriate way to test models as hypotheses (see debate in \citet{beven2012-c} and \citet{clark2012}, for example),

%% Initial and boundary conditions, which determine the initial state of the system and the state along its boundaries, are often unknown \citep{beven2001}. 

%% In future projections of climate models a comparison of an ensemble of models has become standard procedure \citep{beven}.

%% The problem is compounded by the fact that the source code of many hydrological models is not available, making it difficult to understand decisions made by different modelers... \\

%% This has partly arisen because hydrological models are developed in isolation and lack a common interface [...] efforts such as the Framework for Understanding Structural Errors (FUSE) \citep{clark2008}.

%% In many cases the initial and boundary conditions and parameters are considered as random variables rather than fixed, known quantities and a collection of feasible values, perhaps with varying likelihoods, is generated to capture the range of uncertainty present \citep{}. 

%% In distributed, physics-based hydrological modelling, much uncertainty arises from sub-grid parameterisations that are used to represent processes that occur at finer scales than the model grid as well as processes that we do not fully understand \citep{beven2002}. 

%% These ideas are not new: one of the aims of the prediction in ungauged basins was to... Yet, despite some progress, there is a lack...

%% The problem is compounded by the fact that the source code of many hydrological models is not available, making it difficult to understand decisions made by different modelers... \\

%% This has partly arisen because hydrological models are developed in isolation and lack a common interface [...] efforts such as the Framework for Understanding Structural Errors (FUSE) \citep{clark2008}.

%% Models such as... 

%% %% Paragraph ?: establish why it is necessary to couple models
%% Earth system models (also integrated environmental models) are coupled models that simulate interactions between several [...] \citep{valcke2012,laniak2013,nazemi2015} \citep{armstrong2008,laniak2013,whelan2014,nazemi2015} Attempts to couple separate components to create a systems model [...] \citep{jagers2010} [...] This is particularly the case when human-environment interactions are modelled \citep{} [...] The need to couple models arises frequently in hydrology. In some cases this is because the model does not include some [...] For example, most land surface parameterisations do not explicitly model groundwater [...] Conceptually, we know that groundwater may influence the near surface soil moisture [...] \citep{miller2005}. In other situations we may wish to improve processes that are not adequately represented [...] For example, land surface parameterisations do not usually include specific crop classes, so to model [...] it is necessary to incorporate a crop model \citep[e.g.][]{tsarouchi2014}. To model human-environment interactions [...] For example, [...] \\ 

%% %% Paragraph ?: describe current modelling frameworks  
%% The need for couplers was first addressed by the climate modelling community to couple [...] Current modelling frameworks (OpenMI, ...) Component-based frameworks consist of model components that follow a standard component interface to ensure that different components within the same framework interact correctly \citep{valcke2012}. The Earth System Modelling Framework \citep{hill2004} is a component-based modelling framework developed to build complex earth system models \citep{}. It has been applied to [...] \citep[e.g.][]{keller2014} ESMF provides generic component interfaces [...] These frameworks are designed to be run on supercomputers and, as such, [...] steep learning curve [...] There are limited applications of these couplers to hydrology [...] ...\citet{shrestha2014} coupled the Community Land Model, ParFlow and COSMO using the OASIS3 coupler [...] \\

%% The Open Modelling System \citep{}... OpenMI supports temporal and spatial disaggregation to ensure model components operating at different temporal and spatial resolutions [...] \citep{blind2005} OpenMI was originally designed to operate on Windows [...] support for other platforms is variable: it has been ported to Linux, although, according to the project website, it is only tested on one Linux distribution (OpenSUSE 11.0, 64-bit) while Mac-users (?) To port OpenMI to Linux the Mono compiler [...] "Mono compiler does not support parallel computing" Furthermore, it is unclear whether the development cycle for the Linux version follows that of the main Windows version. [...] For an existing model to be OpenMI-compliant it is necessary to represent the model as a C# class implementing a set of operations defined by the OpenMI standard \citep{}. This is relatively straightforward if the original model is written in a supported language (.NET, C#) \citep{}. Bearing in mind that the typical OpenMI users are scientists, not programmers, this can be non-trivial \citep{bulatewicz2012,lu2012}. \\

%% The main disadvantage with model couplers is that they require substantial modification of the original source code to be compliant \citep{}. This is unssatisfactory, because, assuming the efforts to make the model compliant is not carried out by the core developers, it removes the model from the development cycle. For this reason, "...there is a desire to leave component models unchanged..." assuming that the development of the model is seperate from efforts to [...] OpenMI, this means [...] \citep{armstrong2008} (also \citep{gregerson2007} This was the main reason for the development of the Bespoke Framework Generator, [...] uses XML metadata to create a model framework (the "run-time infrastructure that calls component models and allows them to communicate" \citep{armstrong2008}). \\

%% Coupling models by transferring model input/output is an example of loose model coupling \citep{kamp2007}. While this approach has performance disadvantages... \\

 %% Advances in technology... [link together distributed database and processors] Coupling existing models [...] allowing the development of individual models to continue independently [...] In addition, it encourages parsimony because only model compoenents relevant to particular scientific questions need to be included in the framework \citep{lenton2007} For example, [...] A review of existing model coupling tools is provided by \citet{jagers2010} [...] In hydrology, there have been numerous attempts to develop model coupling framework [...] \\ 

%% The main purpose of land surface models is to provide the lower boundary condition to global and regional climate models \citep{best2011} The application of these models to hydrological problems [...] The earth system model components is non-trivial and requires [...] \citep{turuncoglu2011} Furthermore, running such models over all but the smallest study areas on personal computers is time consuming. This fact has important consequences for the reproducibility of scientific results [...] Not all researchers have the ability and resources to install [...] 

%% For example, \citet{gober2015} draws attention to the shortcomings of using the concept of social memory used by \citet{dibaldassarre2015} to simulate interactions between flood risk and society...
%% Coupling models rather than developing monolithic models is also valuable in order to prevent obfuscating system signals... \citep{bohensky2014}
%% As in traditional hydrological modelling, it is important to get the right results for the right reasons in order to gain insight into the human-water system \citep{troy2015-a}.


%% Managing this complexity and bringing together models and data to understand coupled human-water systems requires specialist tools... 

%% As an emerging area of research there are many opportunities for future research activities. For example, \citet{troy2015} highlights the way in which behavioural responses... Models as multiple working hypotheses would benefit from a common interface \citep{}. Furthermore, socio-hydrology is subject to high levels of uncertainty... \citep{dibaldassarre2015,blair2016}. Under these circumstances it is beneficial to implement models as coupled-component models so that the uncertainty can be effectively communicated... \citep{clark2011,clark2015-a,clark2015-b}. 

%% tim foster?

%% Model development in socio-hydrology is data-intensive, requiring both quantitative data and qualititative data to understand the behaviour of social systems in relation to water use \citep{kelly2013}. \\

%% Integrated environmental modelling is a systems approach where various models and data are combined to address specific questions related to environmental management and assessment \citep{bastin2012,laniak2013}. It brings together the knowledge and expertise of various scientific communities and, in doing so, increases the collective knowledge of the system \citep{laniak2013}.

%% In a loose-coupling approach model components must adopt a standard interface but the internal model structure is left untouched \citep{goodall2011}. 

%% For developers of model components this provides greater freedom to implement model equations in the most efficient way possible, while developers of the model at the systems level have greater flexibility about the types of model that can be coupled \citep{goodall2011}.

 %% \citet{salas2012} defines this type of model coupling as an example of business integration in which system components... \citet{salas2012} developed... \\

%% Applications of OpenMI... For example, \citet{jackson} developed a coupled model to represent feedbacks between... %%
%% These frameworks are designed for the earth system modelling community and optimised for High Performance Computing \citep{goodall2011}. 
%% Bearing in mind that prototypical OpenMI users are scientists and engineers, rather than professional programmers, this can be non-trivial \citep{bulatewicz2012,lu2012}. 

%% Existing component-based frameworks result in tight-coupling applications... A tight-coupling approach involves combining the code of the original models to create a single modelling application \citep{goodall2011}. 

%% Existing frameworks for model coupling impose constraints on modellers such as requiring knowledge of a particular programming language, depending on a certain platform (e.g. Windows, Unix (Linux)). 

%% The concept supports the notion of 'Models of Everywhere' foreseen by \citet{beven2007}.

%% OpenMI supports temporal and spatial disaggregation to ensure model components operating at different temporal and spatial resolutions \citep{blind2005}. 
%% \citet{salas2015} details three main approaches to hydrological model coupling, which they refer to as data integration, business integration and presentation integration. With data integration system components use a shared data repository. All components can write data to, and retrieve data from, the repository. In a business integration approach
%% Loose and tight model coupling \citep{kelly2013}
%% There are considerable technical challenges associated with coupling legacy models which were not necessarily designed... \citep{kelly2013}. \\

%% In this context several model coupling frameworks have been developed, including the Earth Systems Modeling Framework... Component-based frameworks consist of model components that follow a standard component interface to ensure that different components within the same framework interact correctly \citep{valcke2012}. The Earth System Modelling Framework \citep{hill2004} is a component-based modelling framework developed to build complex earth system models \citep{}. It has been applied to [...] \citep[e.g.][]{keller2014} ESMF provides generic component interfaces [...] These frameworks are designed to be run on supercomputers and, as such, [...] steep learning curve [...]
%% These frameworks are designed to optimise model performance and run on supercomputers 

%% The need for couplers was first addressed by the climate modelling community to couple separate components of earth system models. In this context several model coupling frameworks have been developed, including the Earth Systems Modeling Framework... These frameworks are designed to optimise model performance and run on supercomputers. In hydrology, the Open Modeling Interface (OpenMI) \citep{} was developed to... Current modelling frameworks (OpenMI, ...) Component-based frameworks consist of model components that follow a standard component interface to ensure that different components within the same framework interact correctly \citep{valcke2012}. The Earth System Modelling Framework \citep{hill2004} is a component-based modelling framework developed to build complex earth system models \citep{}. It has been applied to [...] \citep[e.g.][]{keller2014} ESMF provides generic component interfaces [...] These frameworks are designed to be run on supercomputers and, as such, [...] steep learning curve [...] There are limited applications of these couplers to hydrology [...] ...\citet{shrestha2014} coupled the Community Land Model, ParFlow and COSMO using the OASIS3 coupler [...] \\

%% Furthermore it should be possible to provide these workflows as web services that form the basis of decision support systems. - web services in Discussion

%% Socio-hydrology is the study of the ``dynamics and coevolution of coupled human-water systems" \citep{sivapalan2012}. Integrated environmental modelling is... \\

%% Earth system models (also integrated environmental models) are coupled models that simulate interactions between several [...] \citep{valcke2012,laniak2013,nazemi2015} \citep{armstrong2008,laniak2013,whelan2014,nazemi2015} Attempts to couple separate components to create a systems model [...] \citep{jagers2010} [...] This is particularly the case when human-environment interactions are modelled \citep{} [...] The need to couple models arises frequently in hydrology. In some cases this is because the model does not include some [...] For example, most land surface parameterisations do not explicitly model groundwater [...] Conceptually, we know that groundwater may influence the near surface soil moisture [...] \citep{miller2005}. In other situations we may wish to improve processes that are not adequately represented [...] For example, land surface parameterisations do not usually include specific crop classes, so to model [...] it is necessary to incorporate a crop model \citep[e.g.][]{tsarouchi2014}. To model human-environment interactions [...] For example, [...] \\ 

%% Paragraph ?: describe current modelling frameworks  

%% OpenMI, this means [...] \citep{armstrong2008} (also \citep{gregerson2007}

%% The main disadvantage with model couplers is that they require substantial modification of the original source code to be compliant \citep{}. This is unsatisfactory, because, assuming the efforts to make the model compliant is not carried out by the core developers, it removes the model from the development cycle. For this reason, ``...there is a desire to leave component models unchanged..." assuming that the development of the model is seperate from efforts to [...] 
%% OpenMI, this means [...] \citep{armstrong2008} (also \citep{gregerson2007} %% This was the main reason for the development of the Bespoke Framework Generator, [...] uses XML metadata to create a model framework (the "run-time infrastructure that calls component models and allows them to communicate" \citep{armstrong2008}). \\




\chapter{Conclusion}

TODO

%% \begin{thebibliography}{123}
%% \addcontentsline{toc}{chapter}{Bibliography}
%% \raggedright

\bibliographystyle{apalike}
\bibliography{thesis_refs}
%% \bibitem{bibtex} It is more convinient and faster to use \texttt{bibtex} instead 
%% of writing your bibliography manually.

%% \bibitem{jabref}
%% You can even use a tool like \texttt{jabref} to manage and maintain your 
%% database of references.

%% \end{thebibliography}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% If you print your dissertation for yourself or as a present for
% family, friends or colleagues you probably should use a different
% layout which does not fulfill the College requirements but which
% can look much better.
%
% For further information and for professional layouting and
% printing services please visit www.PrettyPrinting.net
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
